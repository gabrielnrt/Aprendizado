{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbecb993-5250-49f7-a82e-74cbe87cdd82",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03551cd-0e81-4915-b40f-24cb554bc7a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fc5286-6e2c-484a-886d-3274002ea3a3",
   "metadata": {},
   "source": [
    "Nesta pasta da biblioteca do TensorFlow, veremos como criar redes neurais. Como a introdução será grande, então vamos dividí-la em subseções.\n",
    "\n",
    "A menor unidade de uma rede é o **neurônio**, que recebe os dados, e cada tipo de dado possui um **peso** (\"importância\"). \n",
    "\n",
    "**O aprendizado da rede se dá pelo ajuste desses pesos**, e essa ideia será retomada algumas vezes ao longo deste notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4dca87-86ec-4d61-8d00-8951c914e8b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Função de Ativação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa782f9-ee2e-4324-adc3-d8824e412533",
   "metadata": {},
   "source": [
    "Cada neurônio é dotado de uma **função de ativação**. As funções de ativação costumam ser as seguintes, considerando $x$ como a soma ponderada das entradas:\n",
    "\n",
    "\n",
    "* **Threshold**: esta é a função degrau $f(x)$ que é $0$ se $x<0$ e $1$ se $x \\geq 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99bbfb02-6e93-457d-ba03-cd289c3f0bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Função Threshold (degrau)')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import linspace, heaviside\n",
    "from pylab import legend, title, xlabel, ylabel, plot\n",
    "\n",
    "x = linspace(-1,1,20)\n",
    "y = heaviside(x,1)\n",
    "\n",
    "plot(x,y)\n",
    "xlabel('x')\n",
    "ylabel('$f(x)$')\n",
    "title('Função Threshold (degrau)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae559070-c812-4959-b0b7-1dcb2f5adf63",
   "metadata": {},
   "source": [
    "* **Sigmoid**: ela costuma ser usada em modelos de regressão logistica, e nas camadas de saída (este conceito será explicado depois). A função é dada por\n",
    "\n",
    "$  \\LARGE f(x) = \\frac{1}{1 + e^{-x}} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecff8492-8a5b-4733-8f24-e9296810f260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Função Sigmoid')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import e\n",
    "\n",
    "x = linspace(-10,10,100)\n",
    "y = 1/(1 + e**(-x))\n",
    "\n",
    "plot(x,y)\n",
    "\n",
    "xlabel('x')\n",
    "ylabel('$f(x)$')\n",
    "title('Função Sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdfabfe-9043-4e69-8c40-b334b989b207",
   "metadata": {},
   "source": [
    "* **Relu**: é uma abreviação para \"Rectified linear unit\", que é uma função $f(x) = 0$ se $x \\leq 0$ e $f(x) = x$ se $x > 0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7029d4-314d-4ddd-81c3-f61d936d9110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Função Relu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import maximum\n",
    "\n",
    "def relu(x):\n",
    "    return maximum(0,x)\n",
    "\n",
    "x = linspace(-1,1,20)\n",
    "y = relu(x)\n",
    "\n",
    "plot(x,y)\n",
    "\n",
    "xlabel('x')\n",
    "ylabel('$f(x)$')\n",
    "title('Função Relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04705cbb-358e-4a48-a5ce-0bcc7bec4559",
   "metadata": {},
   "source": [
    "* **Tangente Hiperbólica**: como o próprio nome diz, essa é a função tangente hiperbólica dada por\n",
    "\n",
    "$\\Large f(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec40e49a-48e2-4cb3-9e2f-93da9c3790ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Tangente Hiperbólica')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import tanh\n",
    "\n",
    "x = linspace(-10,10,100)\n",
    "y = tanh(x)\n",
    "\n",
    "plot(x,y)\n",
    "\n",
    "xlabel('x')\n",
    "ylabel('$f(x)$')\n",
    "title('Tangente Hiperbólica')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f762d35-177c-494d-8188-013651631ad0",
   "metadata": {},
   "source": [
    "Obs: embora seja muito parecida com a sigmoide, a tangente hiperbólica pode assumir valores negativos, enquanto que a sigmoide não."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4256cc2-9e12-420a-bcd9-e1e7a9d53c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Estrutura de uma rede"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cb06d9-d8ba-4c1f-a158-7292adf4e2e6",
   "metadata": {},
   "source": [
    "Agora que vimos o que há dentro de cada neurônio, vejamos como se dá a estrutura de uma rede neural. As redes costumas estar organizadas em\n",
    "\n",
    "* **Camada de entrada**: constituída de atributos;\n",
    "\n",
    "* **Camadas Ocultas**: constituída pelos neurônios;\n",
    "\n",
    "* **Camada de Saída**: constituída de neurônios. O número de neurônios é igual ao número de resultados (classes) possíveis.\n",
    "\n",
    "Em geral, o número de neurônios necessŕios para construir a rede é dado pela relação $(a+b)/2$, onde $a$ é a quantidade de atributos (característica), e $b$ é a quantidade de classes (resultados possíveis).\n",
    "\n",
    "Uma vez que todos os registros passaram pela rede, dizemos que uma **epoch** foi completa. Quando isso ocorre, \"entra em cena\" a chamada **função de custo/prejuízo**, que avalia a diferença entre a previsão e o valor real. Um exemplo desse tipo de função é o RMS - root mean square.\n",
    "\n",
    "Uma vez calculado o erro, a rede atualiza os pesos, e isso ocorre a cada epoch.\n",
    "\n",
    "Até achar os melhores pesos, o método usado para atualizar a cada epoch é o **Gradient Descent**, que usa o gradiente - vide cálculo de várias variáveis - para achar um ponto de extremo que minimize os erros. Esse método funciona bem para funções com concavidade para cima. Para funções que não tem essa propriedade, é usado o **Stochastic Gradient Descent**.\n",
    "\n",
    "\n",
    "Descrevendo o funcionamento dessa maneira, temos a impressão de que o modelo fica viciado no sentido de que - depois de várias epochs - ele fica super-ajustado aos dados de treino apenas. Contudo, a rede possui formas de evitar esse super-ajuste chamadas de **Regularização**. A técnica de Regularização mais conhecida é o **dropout**, onde um ou mais neurônios são descartados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5c061-9f60-4fd4-8ebd-9ff693daafa3",
   "metadata": {},
   "source": [
    "Agora que vimos o que é uma rede neural e suas características, vamos aplicá-lo na prática com os dados do Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8383aa19-d4ed-4aa7-b6ba-cb199962aa9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dados Iniciais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb6390-47b5-4fe2-9c90-a072d6fc16b4",
   "metadata": {},
   "source": [
    "Como dito anteriormente, vamos importar os dados do Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f80b6fa-f11c-4507-b3c1-5a39ab954a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import argmax\n",
    "\n",
    "\n",
    "base = datasets.load_iris()\n",
    "\n",
    "previsores = base.data\n",
    "\n",
    "classe = base.target\n",
    "\n",
    "classe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e612f28c-7920-4a05-b49e-9945551d6c7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ```np_utils```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d00ce4-7c91-4a82-b485-6c410ad4d013",
   "metadata": {},
   "source": [
    "Como temos 3 tipos de resultados possíveis - Setosa, Virginica e Versicolor - então vamos transformar cada elemento desse array numa linha com 3 colunas. Desta maneira, a camada de saída, que possuirá 3 neurônios, vai atuar em cada coluna desse novo objeto para identificar o tipo de planta.\n",
    "\n",
    "Para fazer isso, digitamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf2fd348-fb23-4243-9afb-2d186f5b5cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 16:53:19.645488: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-03 16:53:19.645551: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "classe_dummy = np_utils.to_categorical(classe)\n",
    "\n",
    "classe_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9b09e4-9305-404b-8667-1c127a2ad26b",
   "metadata": {},
   "source": [
    "Assim, quando temos 1, na primeira coluna e 0 nas demais, então a planta corresponde a uma Setosa, e assim por diante. Deste modo, vamos realizar o fatiamento dos dados em treino e teste da mesma maneira que fizemos em outros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "771c8578-332e-4ff8-8aeb-ce3c6910bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(previsores,\n",
    "                                                                  classe_dummy,\n",
    "                                                                  test_size = 0.3,\n",
    "                                                                  random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de0b6d-80a2-4190-a064-53f2fd6064bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ```Dense()```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55dd68b-cb91-40b9-a1b6-10e9af752d49",
   "metadata": {},
   "source": [
    "Agora que preparamos os dados iniciais, vamos nos dedicar à criação da rede. Para isso precisamos primeiramente de camadas, que podem ser importadas fazendo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2749fee9-434b-423f-b0bc-f4f8d798f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d092eb-85ac-4984-87c5-54e6871ad798",
   "metadata": {},
   "source": [
    "Assim, dentre os argumentos que existem, destacamos\n",
    "\n",
    "* ```units```: número de neurônios;\n",
    "\n",
    "* ```activation```: função de ativação a ser usada. Se não for especificada, o programa vai tomar f(x) = x;\n",
    "\n",
    "* ```input_dim```:  dimensão dos dados da entrada. No nosso caso, ele é igual a 4 pois temos 4 características: comprimeto da pétala, largura da pétala, comprimento da sépala e largura da sépala."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f928bfc9-6bef-4b65-b472-fe0b9d928a19",
   "metadata": {},
   "source": [
    "Posto isso, criemos 3 camadas para o problema do Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08eb254d-4513-4c0a-ad3d-2bfd70b0c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "camada1 = Dense(units = 5, input_dim = 4)\n",
    "\n",
    "camada2 = Dense(units = 4)\n",
    "\n",
    "camada3 = Dense(units = 3, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35793aae-28ff-4979-bd4e-e4755007598f",
   "metadata": {},
   "source": [
    "A primeira camada contém um neurônio a mais por causa do bias (eu acho); já o segundo contém 4 neurônios como devia ser. Por fim, o último possui 3 neurônios pois temos 3 classes (resultados possíveis), que são Setosa, Vericolor e Virginica. \n",
    "\n",
    "Além disso, usamos a função de ativação softmax pois o problema possui mais de duas classes; e com isso geramos uma probabilidade em cada neurônio, similar ao agrupamento difuso (vide o notebook da pasta Skfuzzy sobre o c-means)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbd2bb-a1de-4e43-adb1-61e988009d37",
   "metadata": {},
   "source": [
    "## ```Sequential()```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439edf6-6b65-490d-b63f-0e7b4e9777ac",
   "metadata": {},
   "source": [
    "Com as camadas criadas, vamos nos atentar à estrutura da rede propriamente dita. No caso do Iris, criaremos uma rede sequencial. Importamos essa classe digitando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f2af246-989e-4367-9332-a7760a641904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ea0b8-ddb7-4ebd-b20d-54758026abb0",
   "metadata": {},
   "source": [
    "Obs: A documentação com todos os argumentos, atributos e métodos se encontra em https://www.tensorflow.org/api_docs/python/tf/keras/Sequential.\n",
    "\n",
    "Criamos o modelo fornecendo o parâmetro ```layers``` (camadas) com uma lista contendo as camadas que a rede terá. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da50e914-34ea-4050-b7e6-bf4d63f37d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 16:53:50.573244: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-03 16:53:50.573288: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-03 16:53:50.573320: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ProBook6460b): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "modelo = Sequential(layers = [camada1, camada2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e74bc25-ce53-42fc-a7f8-016f622b83ca",
   "metadata": {},
   "source": [
    "Para adicionar mais camadas, usamos o método ```add```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "851f96dc-4206-4dbe-a753-82222fdb119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.add(camada3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433dc331-8116-44f5-8823-3e23f47b85d4",
   "metadata": {},
   "source": [
    "Podemos ver um resumo do que fizemos até agora usando o método ```summary```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fbfa094-a3e9-4ef8-b39d-9d564438ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 25        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 24        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64\n",
      "Trainable params: 64\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb469d-8731-4db2-82f8-f70a0200649d",
   "metadata": {},
   "source": [
    "Uma vez feito isso, vamos configurar o modelo para o treino, que é feito através do método ```compile```. Dentre os argumentos que existem nesse método, destacamos\n",
    "\n",
    "* ```optimizer```: função que atualiza os pesos. Pode ser ```adadelta```, ```adam```, ```adagrad```, dentre outros. Ver https://www.tensorflow.org/api_docs/python/tf/keras/optimizers. Neste caso, usaremos o ```adam``` pois é um método do tipo *stochastic gradient descent*.\n",
    "\n",
    "* ```loss```: função de perda. Escolheremos a ```categorical_corssentropy``` para o caso do Iris. Caso queiramos ver outras funções, basta acessar https://www.tensorflow.org/api_docs/python/tf/keras/losses na parte de 'Functions'.\n",
    "\n",
    "* ```metrics```: lista com o nome da função para avaliar a precisão do modelo. Usaremos ```accuracy``` neste caso. Demais funções podem ser vistas em https://www.tensorflow.org/api_docs/python/tf/keras/metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1996b7d1-5368-4bd2-8fe0-7d13816f8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(optimizer = 'adam', \n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9638af-3029-4958-9367-326002a74c69",
   "metadata": {},
   "source": [
    "Agora sim, com todo o \"terreno preparado\", vamos treinar nossa rede com o método ```fit```. Esse método possui vários argumentos, que podem ser acessados em https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit. Por hora, vamos nos ater aos seguintes argumentos\n",
    "\n",
    "* ```x```: dados de **treino** contendo as características. No nosso caso ele corresponde aos dados de treino contendo o comprimento e a largura das pétalas e sépalas de cada planta;\n",
    "\n",
    "* ```y```: dados de **treino** contendo os resultados (classe) de cada linha; \n",
    "\n",
    "* ```epochs```: número de vezes que todos os registros passam pela rede. É isso que vai tornar lento o treinamento do modelo;\n",
    "\n",
    "* ```validation_data```: dados de **teste** contendo as instâncias e as classes. Ela costuma ser dada na forma de tupla, na ordem ```(Xteste,Yteste)```\n",
    "\n",
    "Obs: ao contrário dos outros modelos, o ```x``` está em **minúsculo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1570ab6b-770c-4bb8-8048-9ac2e3fa0ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 1s 71ms/step - loss: 4.5296 - accuracy: 0.3238 - val_loss: 3.4406 - val_accuracy: 0.3556\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 4.1152 - accuracy: 0.3238 - val_loss: 3.0931 - val_accuracy: 0.3556\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.7084 - accuracy: 0.3238 - val_loss: 2.7623 - val_accuracy: 0.3556\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.3275 - accuracy: 0.3238 - val_loss: 2.4488 - val_accuracy: 0.3556\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9588 - accuracy: 0.3238 - val_loss: 2.1588 - val_accuracy: 0.3556\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 2.6059 - accuracy: 0.3238 - val_loss: 1.8942 - val_accuracy: 0.3556\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.2987 - accuracy: 0.3238 - val_loss: 1.6527 - val_accuracy: 0.3556\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.0039 - accuracy: 0.3429 - val_loss: 1.4396 - val_accuracy: 0.3778\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.7543 - accuracy: 0.3619 - val_loss: 1.2545 - val_accuracy: 0.4000\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.5347 - accuracy: 0.3810 - val_loss: 1.0990 - val_accuracy: 0.4889\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.3409 - accuracy: 0.4476 - val_loss: 0.9712 - val_accuracy: 0.6222\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0242 - accuracy: 0.62 - 0s 16ms/step - loss: 1.1770 - accuracy: 0.5333 - val_loss: 0.8687 - val_accuracy: 0.6444\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0452 - accuracy: 0.5524 - val_loss: 0.7871 - val_accuracy: 0.7333\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9363 - accuracy: 0.5810 - val_loss: 0.7238 - val_accuracy: 0.7556\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8393 - accuracy: 0.6286 - val_loss: 0.6778 - val_accuracy: 0.7556\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7730 - accuracy: 0.6571 - val_loss: 0.6457 - val_accuracy: 0.7778\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7138 - accuracy: 0.6571 - val_loss: 0.6273 - val_accuracy: 0.7778\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6752 - accuracy: 0.6762 - val_loss: 0.6185 - val_accuracy: 0.7556\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6502 - accuracy: 0.7143 - val_loss: 0.6169 - val_accuracy: 0.7111\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6276 - accuracy: 0.7524 - val_loss: 0.6188 - val_accuracy: 0.6444\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6210 - accuracy: 0.7143 - val_loss: 0.6225 - val_accuracy: 0.6889\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6131 - accuracy: 0.7333 - val_loss: 0.6254 - val_accuracy: 0.7111\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6097 - accuracy: 0.7429 - val_loss: 0.6283 - val_accuracy: 0.7111\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6064 - accuracy: 0.7429 - val_loss: 0.6290 - val_accuracy: 0.7111\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6035 - accuracy: 0.7429 - val_loss: 0.6278 - val_accuracy: 0.7111\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6012 - accuracy: 0.7429 - val_loss: 0.6257 - val_accuracy: 0.7111\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5983 - accuracy: 0.7429 - val_loss: 0.6223 - val_accuracy: 0.7111\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5957 - accuracy: 0.7429 - val_loss: 0.6206 - val_accuracy: 0.7111\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5931 - accuracy: 0.7429 - val_loss: 0.6163 - val_accuracy: 0.7111\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5903 - accuracy: 0.7429 - val_loss: 0.6141 - val_accuracy: 0.7111\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5878 - accuracy: 0.7429 - val_loss: 0.6114 - val_accuracy: 0.7111\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5849 - accuracy: 0.7429 - val_loss: 0.6078 - val_accuracy: 0.7111\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5821 - accuracy: 0.7429 - val_loss: 0.6058 - val_accuracy: 0.7111\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5795 - accuracy: 0.7429 - val_loss: 0.6041 - val_accuracy: 0.7111\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5770 - accuracy: 0.7429 - val_loss: 0.6029 - val_accuracy: 0.7111\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5745 - accuracy: 0.7429 - val_loss: 0.6029 - val_accuracy: 0.6889\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5722 - accuracy: 0.7429 - val_loss: 0.6018 - val_accuracy: 0.6667\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5695 - accuracy: 0.7429 - val_loss: 0.5980 - val_accuracy: 0.6889\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5667 - accuracy: 0.7429 - val_loss: 0.5940 - val_accuracy: 0.7111\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5641 - accuracy: 0.7429 - val_loss: 0.5895 - val_accuracy: 0.7111\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5616 - accuracy: 0.7429 - val_loss: 0.5865 - val_accuracy: 0.7111\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5592 - accuracy: 0.7429 - val_loss: 0.5839 - val_accuracy: 0.7111\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5566 - accuracy: 0.7429 - val_loss: 0.5817 - val_accuracy: 0.7111\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5542 - accuracy: 0.7429 - val_loss: 0.5802 - val_accuracy: 0.7111\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5520 - accuracy: 0.7429 - val_loss: 0.5799 - val_accuracy: 0.7111\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5497 - accuracy: 0.7429 - val_loss: 0.5777 - val_accuracy: 0.7111\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5473 - accuracy: 0.7429 - val_loss: 0.5748 - val_accuracy: 0.7111\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5449 - accuracy: 0.7429 - val_loss: 0.5708 - val_accuracy: 0.7111\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5431 - accuracy: 0.7429 - val_loss: 0.5648 - val_accuracy: 0.7111\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5403 - accuracy: 0.7524 - val_loss: 0.5618 - val_accuracy: 0.7111\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5379 - accuracy: 0.7524 - val_loss: 0.5594 - val_accuracy: 0.7111\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5359 - accuracy: 0.7524 - val_loss: 0.5577 - val_accuracy: 0.7111\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5336 - accuracy: 0.7524 - val_loss: 0.5548 - val_accuracy: 0.7111\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5312 - accuracy: 0.7524 - val_loss: 0.5527 - val_accuracy: 0.7111\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5298 - accuracy: 0.7524 - val_loss: 0.5519 - val_accuracy: 0.7111\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5267 - accuracy: 0.7524 - val_loss: 0.5482 - val_accuracy: 0.7111\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5246 - accuracy: 0.7524 - val_loss: 0.5444 - val_accuracy: 0.7111\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5229 - accuracy: 0.7619 - val_loss: 0.5413 - val_accuracy: 0.7111\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5206 - accuracy: 0.7619 - val_loss: 0.5405 - val_accuracy: 0.7111\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5185 - accuracy: 0.7619 - val_loss: 0.5395 - val_accuracy: 0.7111\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5163 - accuracy: 0.7619 - val_loss: 0.5405 - val_accuracy: 0.7111\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5151 - accuracy: 0.7524 - val_loss: 0.5412 - val_accuracy: 0.7111\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5125 - accuracy: 0.7524 - val_loss: 0.5386 - val_accuracy: 0.7111\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5104 - accuracy: 0.7524 - val_loss: 0.5368 - val_accuracy: 0.7111\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5085 - accuracy: 0.7524 - val_loss: 0.5333 - val_accuracy: 0.7111\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5065 - accuracy: 0.7524 - val_loss: 0.5308 - val_accuracy: 0.7111\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5039 - accuracy: 0.7619 - val_loss: 0.5254 - val_accuracy: 0.7111\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5038 - accuracy: 0.7619 - val_loss: 0.5198 - val_accuracy: 0.7111\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5008 - accuracy: 0.7714 - val_loss: 0.5175 - val_accuracy: 0.7111\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4987 - accuracy: 0.7714 - val_loss: 0.5160 - val_accuracy: 0.7111\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4968 - accuracy: 0.7714 - val_loss: 0.5147 - val_accuracy: 0.7111\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4951 - accuracy: 0.7714 - val_loss: 0.5127 - val_accuracy: 0.7111\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4932 - accuracy: 0.7810 - val_loss: 0.5099 - val_accuracy: 0.7111\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4914 - accuracy: 0.7905 - val_loss: 0.5076 - val_accuracy: 0.7111\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4896 - accuracy: 0.7905 - val_loss: 0.5066 - val_accuracy: 0.7111\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4877 - accuracy: 0.7905 - val_loss: 0.5067 - val_accuracy: 0.7111\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4861 - accuracy: 0.7810 - val_loss: 0.5070 - val_accuracy: 0.7111\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4840 - accuracy: 0.7714 - val_loss: 0.5065 - val_accuracy: 0.7111\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4822 - accuracy: 0.7714 - val_loss: 0.5054 - val_accuracy: 0.7111\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4805 - accuracy: 0.7714 - val_loss: 0.5038 - val_accuracy: 0.7111\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4787 - accuracy: 0.7810 - val_loss: 0.5025 - val_accuracy: 0.7111\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4771 - accuracy: 0.7714 - val_loss: 0.5017 - val_accuracy: 0.7111\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4756 - accuracy: 0.7810 - val_loss: 0.4989 - val_accuracy: 0.7111\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4737 - accuracy: 0.7810 - val_loss: 0.4987 - val_accuracy: 0.7111\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4719 - accuracy: 0.7810 - val_loss: 0.4982 - val_accuracy: 0.7111\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4707 - accuracy: 0.7714 - val_loss: 0.4985 - val_accuracy: 0.7111\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4689 - accuracy: 0.7810 - val_loss: 0.4961 - val_accuracy: 0.7111\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4672 - accuracy: 0.7905 - val_loss: 0.4952 - val_accuracy: 0.7111\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4656 - accuracy: 0.7905 - val_loss: 0.4931 - val_accuracy: 0.7111\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4638 - accuracy: 0.7810 - val_loss: 0.4904 - val_accuracy: 0.7111\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4621 - accuracy: 0.7810 - val_loss: 0.4877 - val_accuracy: 0.7111\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4609 - accuracy: 0.7905 - val_loss: 0.4850 - val_accuracy: 0.7111\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4590 - accuracy: 0.7905 - val_loss: 0.4855 - val_accuracy: 0.7111\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4579 - accuracy: 0.7810 - val_loss: 0.4857 - val_accuracy: 0.7111\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4560 - accuracy: 0.8000 - val_loss: 0.4830 - val_accuracy: 0.7111\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4545 - accuracy: 0.7905 - val_loss: 0.4791 - val_accuracy: 0.7111\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4529 - accuracy: 0.8000 - val_loss: 0.4767 - val_accuracy: 0.7333\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4512 - accuracy: 0.8000 - val_loss: 0.4749 - val_accuracy: 0.7333\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4497 - accuracy: 0.8000 - val_loss: 0.4744 - val_accuracy: 0.7333\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4481 - accuracy: 0.8000 - val_loss: 0.4743 - val_accuracy: 0.7333\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4467 - accuracy: 0.8000 - val_loss: 0.4733 - val_accuracy: 0.7333\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4452 - accuracy: 0.8000 - val_loss: 0.4725 - val_accuracy: 0.7333\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4437 - accuracy: 0.8095 - val_loss: 0.4702 - val_accuracy: 0.7333\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4424 - accuracy: 0.8095 - val_loss: 0.4692 - val_accuracy: 0.7333\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4408 - accuracy: 0.8095 - val_loss: 0.4678 - val_accuracy: 0.7333\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4394 - accuracy: 0.8095 - val_loss: 0.4668 - val_accuracy: 0.7333\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4382 - accuracy: 0.8190 - val_loss: 0.4650 - val_accuracy: 0.7556\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4364 - accuracy: 0.8095 - val_loss: 0.4654 - val_accuracy: 0.7333\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4352 - accuracy: 0.8095 - val_loss: 0.4650 - val_accuracy: 0.7333\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4339 - accuracy: 0.8095 - val_loss: 0.4641 - val_accuracy: 0.7333\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4321 - accuracy: 0.8095 - val_loss: 0.4598 - val_accuracy: 0.7556\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4303 - accuracy: 0.8190 - val_loss: 0.4557 - val_accuracy: 0.7778\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4290 - accuracy: 0.8286 - val_loss: 0.4498 - val_accuracy: 0.8000\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4284 - accuracy: 0.8381 - val_loss: 0.4435 - val_accuracy: 0.8222\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4268 - accuracy: 0.8476 - val_loss: 0.4407 - val_accuracy: 0.8222\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4255 - accuracy: 0.8476 - val_loss: 0.4394 - val_accuracy: 0.8222\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4243 - accuracy: 0.8476 - val_loss: 0.4402 - val_accuracy: 0.8222\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4226 - accuracy: 0.8476 - val_loss: 0.4418 - val_accuracy: 0.8222\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4208 - accuracy: 0.8571 - val_loss: 0.4409 - val_accuracy: 0.8222\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4195 - accuracy: 0.8571 - val_loss: 0.4403 - val_accuracy: 0.8222\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.8571 - val_loss: 0.4391 - val_accuracy: 0.8222\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4167 - accuracy: 0.8571 - val_loss: 0.4388 - val_accuracy: 0.8222\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4153 - accuracy: 0.8571 - val_loss: 0.4374 - val_accuracy: 0.8222\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4140 - accuracy: 0.8571 - val_loss: 0.4374 - val_accuracy: 0.8222\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4125 - accuracy: 0.8667 - val_loss: 0.4378 - val_accuracy: 0.8000\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4113 - accuracy: 0.8571 - val_loss: 0.4380 - val_accuracy: 0.7778\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4101 - accuracy: 0.8571 - val_loss: 0.4380 - val_accuracy: 0.7778\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4088 - accuracy: 0.8571 - val_loss: 0.4351 - val_accuracy: 0.7778\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4075 - accuracy: 0.8667 - val_loss: 0.4292 - val_accuracy: 0.8222\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4057 - accuracy: 0.8476 - val_loss: 0.4243 - val_accuracy: 0.8222\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4045 - accuracy: 0.8476 - val_loss: 0.4206 - val_accuracy: 0.8444\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4038 - accuracy: 0.8476 - val_loss: 0.4175 - val_accuracy: 0.8444\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4030 - accuracy: 0.8667 - val_loss: 0.4160 - val_accuracy: 0.8444\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4011 - accuracy: 0.8571 - val_loss: 0.4170 - val_accuracy: 0.8444\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3998 - accuracy: 0.8476 - val_loss: 0.4175 - val_accuracy: 0.8444\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3980 - accuracy: 0.8571 - val_loss: 0.4167 - val_accuracy: 0.8444\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3967 - accuracy: 0.8571 - val_loss: 0.4163 - val_accuracy: 0.8444\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3954 - accuracy: 0.8571 - val_loss: 0.4157 - val_accuracy: 0.8444\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3941 - accuracy: 0.8571 - val_loss: 0.4132 - val_accuracy: 0.8444\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3928 - accuracy: 0.8667 - val_loss: 0.4139 - val_accuracy: 0.8444\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3914 - accuracy: 0.8667 - val_loss: 0.4152 - val_accuracy: 0.8222\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3901 - accuracy: 0.8762 - val_loss: 0.4147 - val_accuracy: 0.8222\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3890 - accuracy: 0.8762 - val_loss: 0.4144 - val_accuracy: 0.8222\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3882 - accuracy: 0.8762 - val_loss: 0.4106 - val_accuracy: 0.8444\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3862 - accuracy: 0.8762 - val_loss: 0.4086 - val_accuracy: 0.8444\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3852 - accuracy: 0.8667 - val_loss: 0.4085 - val_accuracy: 0.8444\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3839 - accuracy: 0.8762 - val_loss: 0.4082 - val_accuracy: 0.8444\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3826 - accuracy: 0.8762 - val_loss: 0.4070 - val_accuracy: 0.8444\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3817 - accuracy: 0.8762 - val_loss: 0.4017 - val_accuracy: 0.8444\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3803 - accuracy: 0.8857 - val_loss: 0.3992 - val_accuracy: 0.8444\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3796 - accuracy: 0.8762 - val_loss: 0.4002 - val_accuracy: 0.8444\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3775 - accuracy: 0.8857 - val_loss: 0.3986 - val_accuracy: 0.8444\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3763 - accuracy: 0.8857 - val_loss: 0.3971 - val_accuracy: 0.8444\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3751 - accuracy: 0.8857 - val_loss: 0.3952 - val_accuracy: 0.8444\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3739 - accuracy: 0.8857 - val_loss: 0.3922 - val_accuracy: 0.8667\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3728 - accuracy: 0.8762 - val_loss: 0.3919 - val_accuracy: 0.8667\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3713 - accuracy: 0.8857 - val_loss: 0.3930 - val_accuracy: 0.8444\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3699 - accuracy: 0.8857 - val_loss: 0.3941 - val_accuracy: 0.8444\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3685 - accuracy: 0.8952 - val_loss: 0.3960 - val_accuracy: 0.8444\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3677 - accuracy: 0.8952 - val_loss: 0.3966 - val_accuracy: 0.8444\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3666 - accuracy: 0.8857 - val_loss: 0.3946 - val_accuracy: 0.8444\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3649 - accuracy: 0.8952 - val_loss: 0.3875 - val_accuracy: 0.8444\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.8952 - val_loss: 0.3810 - val_accuracy: 0.8667\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3630 - accuracy: 0.9143 - val_loss: 0.3773 - val_accuracy: 0.8667\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3620 - accuracy: 0.9048 - val_loss: 0.3763 - val_accuracy: 0.8667\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3605 - accuracy: 0.9143 - val_loss: 0.3761 - val_accuracy: 0.8667\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3590 - accuracy: 0.9143 - val_loss: 0.3763 - val_accuracy: 0.8667\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3575 - accuracy: 0.9143 - val_loss: 0.3788 - val_accuracy: 0.8667\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3560 - accuracy: 0.8952 - val_loss: 0.3798 - val_accuracy: 0.8667\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3549 - accuracy: 0.8857 - val_loss: 0.3795 - val_accuracy: 0.8444\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3540 - accuracy: 0.8952 - val_loss: 0.3767 - val_accuracy: 0.8667\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3525 - accuracy: 0.8952 - val_loss: 0.3758 - val_accuracy: 0.8667\n",
      "Epoch 173/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3515 - accuracy: 0.9048 - val_loss: 0.3729 - val_accuracy: 0.8667\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3496 - accuracy: 0.9048 - val_loss: 0.3751 - val_accuracy: 0.8667\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3485 - accuracy: 0.9048 - val_loss: 0.3764 - val_accuracy: 0.8444\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3478 - accuracy: 0.8952 - val_loss: 0.3811 - val_accuracy: 0.8444\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3474 - accuracy: 0.9048 - val_loss: 0.3825 - val_accuracy: 0.8444\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3463 - accuracy: 0.9048 - val_loss: 0.3796 - val_accuracy: 0.8444\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3452 - accuracy: 0.8952 - val_loss: 0.3739 - val_accuracy: 0.8444\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3433 - accuracy: 0.8952 - val_loss: 0.3719 - val_accuracy: 0.8444\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3409 - accuracy: 0.9048 - val_loss: 0.3646 - val_accuracy: 0.8667\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3410 - accuracy: 0.9143 - val_loss: 0.3564 - val_accuracy: 0.9111\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3391 - accuracy: 0.9143 - val_loss: 0.3541 - val_accuracy: 0.9111\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3382 - accuracy: 0.9143 - val_loss: 0.3522 - val_accuracy: 0.8889\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3369 - accuracy: 0.9143 - val_loss: 0.3475 - val_accuracy: 0.8889\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3368 - accuracy: 0.9143 - val_loss: 0.3444 - val_accuracy: 0.8889\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3359 - accuracy: 0.9143 - val_loss: 0.3451 - val_accuracy: 0.8889\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3340 - accuracy: 0.9143 - val_loss: 0.3456 - val_accuracy: 0.8889\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3322 - accuracy: 0.9143 - val_loss: 0.3457 - val_accuracy: 0.8889\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4157 - accuracy: 0.87 - 0s 15ms/step - loss: 0.3298 - accuracy: 0.9143 - val_loss: 0.3505 - val_accuracy: 0.8667\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3287 - accuracy: 0.9238 - val_loss: 0.3557 - val_accuracy: 0.8667\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3281 - accuracy: 0.9333 - val_loss: 0.3553 - val_accuracy: 0.8667\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3270 - accuracy: 0.9333 - val_loss: 0.3493 - val_accuracy: 0.8667\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3250 - accuracy: 0.9238 - val_loss: 0.3456 - val_accuracy: 0.8889\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3241 - accuracy: 0.9238 - val_loss: 0.3412 - val_accuracy: 0.9111\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3229 - accuracy: 0.9143 - val_loss: 0.3403 - val_accuracy: 0.9111\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3215 - accuracy: 0.9238 - val_loss: 0.3420 - val_accuracy: 0.9111\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3206 - accuracy: 0.9238 - val_loss: 0.3439 - val_accuracy: 0.8667\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3190 - accuracy: 0.9238 - val_loss: 0.3417 - val_accuracy: 0.8889\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3183 - accuracy: 0.9238 - val_loss: 0.3351 - val_accuracy: 0.9111\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3166 - accuracy: 0.9143 - val_loss: 0.3312 - val_accuracy: 0.8889\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3156 - accuracy: 0.9143 - val_loss: 0.3306 - val_accuracy: 0.9111\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3143 - accuracy: 0.9143 - val_loss: 0.3306 - val_accuracy: 0.9111\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3129 - accuracy: 0.9143 - val_loss: 0.3290 - val_accuracy: 0.9111\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3120 - accuracy: 0.9143 - val_loss: 0.3257 - val_accuracy: 0.8889\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3109 - accuracy: 0.9143 - val_loss: 0.3232 - val_accuracy: 0.8889\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3101 - accuracy: 0.9143 - val_loss: 0.3216 - val_accuracy: 0.8889\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3091 - accuracy: 0.9143 - val_loss: 0.3270 - val_accuracy: 0.9111\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3060 - accuracy: 0.9238 - val_loss: 0.3323 - val_accuracy: 0.8889\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3072 - accuracy: 0.9429 - val_loss: 0.3400 - val_accuracy: 0.8667\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3062 - accuracy: 0.9429 - val_loss: 0.3382 - val_accuracy: 0.8667\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3046 - accuracy: 0.9429 - val_loss: 0.3380 - val_accuracy: 0.8667\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3031 - accuracy: 0.9429 - val_loss: 0.3322 - val_accuracy: 0.8667\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3013 - accuracy: 0.9429 - val_loss: 0.3263 - val_accuracy: 0.9111\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3005 - accuracy: 0.9333 - val_loss: 0.3210 - val_accuracy: 0.9111\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2985 - accuracy: 0.9238 - val_loss: 0.3199 - val_accuracy: 0.9111\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2974 - accuracy: 0.9333 - val_loss: 0.3193 - val_accuracy: 0.9111\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2961 - accuracy: 0.9333 - val_loss: 0.3156 - val_accuracy: 0.9111\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2951 - accuracy: 0.9238 - val_loss: 0.3137 - val_accuracy: 0.9111\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2946 - accuracy: 0.9238 - val_loss: 0.3166 - val_accuracy: 0.9111\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2927 - accuracy: 0.9333 - val_loss: 0.3152 - val_accuracy: 0.9111\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2916 - accuracy: 0.9333 - val_loss: 0.3109 - val_accuracy: 0.9111\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2901 - accuracy: 0.9238 - val_loss: 0.3083 - val_accuracy: 0.9111\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2896 - accuracy: 0.9143 - val_loss: 0.3062 - val_accuracy: 0.9111\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2878 - accuracy: 0.9238 - val_loss: 0.3078 - val_accuracy: 0.9111\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2868 - accuracy: 0.9333 - val_loss: 0.3062 - val_accuracy: 0.9111\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2852 - accuracy: 0.9333 - val_loss: 0.3022 - val_accuracy: 0.9111\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2844 - accuracy: 0.9143 - val_loss: 0.2985 - val_accuracy: 0.8889\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2834 - accuracy: 0.9143 - val_loss: 0.2985 - val_accuracy: 0.9111\n",
      "Epoch 230/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2819 - accuracy: 0.9143 - val_loss: 0.2996 - val_accuracy: 0.9111\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2806 - accuracy: 0.9333 - val_loss: 0.3008 - val_accuracy: 0.9111\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2793 - accuracy: 0.9333 - val_loss: 0.3032 - val_accuracy: 0.9111\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2785 - accuracy: 0.9333 - val_loss: 0.3058 - val_accuracy: 0.9111\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2779 - accuracy: 0.9429 - val_loss: 0.3051 - val_accuracy: 0.9111\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2769 - accuracy: 0.9333 - val_loss: 0.3001 - val_accuracy: 0.9111\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2750 - accuracy: 0.9333 - val_loss: 0.2959 - val_accuracy: 0.9111\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2738 - accuracy: 0.9333 - val_loss: 0.2903 - val_accuracy: 0.9111\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2727 - accuracy: 0.9333 - val_loss: 0.2875 - val_accuracy: 0.9111\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2717 - accuracy: 0.9238 - val_loss: 0.2849 - val_accuracy: 0.9111\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2709 - accuracy: 0.9143 - val_loss: 0.2833 - val_accuracy: 0.9111\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2699 - accuracy: 0.9143 - val_loss: 0.2817 - val_accuracy: 0.9111\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2690 - accuracy: 0.9238 - val_loss: 0.2842 - val_accuracy: 0.9111\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2671 - accuracy: 0.9333 - val_loss: 0.2848 - val_accuracy: 0.9111\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2665 - accuracy: 0.9333 - val_loss: 0.2853 - val_accuracy: 0.9111\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2648 - accuracy: 0.9333 - val_loss: 0.2810 - val_accuracy: 0.9111\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2637 - accuracy: 0.9333 - val_loss: 0.2778 - val_accuracy: 0.9333\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2627 - accuracy: 0.9238 - val_loss: 0.2731 - val_accuracy: 0.9111\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2619 - accuracy: 0.9238 - val_loss: 0.2708 - val_accuracy: 0.9111\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2608 - accuracy: 0.9238 - val_loss: 0.2689 - val_accuracy: 0.9111\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2602 - accuracy: 0.9238 - val_loss: 0.2696 - val_accuracy: 0.9111\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2583 - accuracy: 0.9333 - val_loss: 0.2717 - val_accuracy: 0.9333\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2573 - accuracy: 0.9333 - val_loss: 0.2748 - val_accuracy: 0.9111\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2558 - accuracy: 0.9333 - val_loss: 0.2754 - val_accuracy: 0.9111\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2546 - accuracy: 0.9333 - val_loss: 0.2722 - val_accuracy: 0.9111\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2534 - accuracy: 0.9333 - val_loss: 0.2714 - val_accuracy: 0.9111\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2523 - accuracy: 0.9333 - val_loss: 0.2671 - val_accuracy: 0.9333\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2511 - accuracy: 0.9238 - val_loss: 0.2611 - val_accuracy: 0.9111\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2510 - accuracy: 0.9333 - val_loss: 0.2566 - val_accuracy: 0.9111\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2505 - accuracy: 0.9238 - val_loss: 0.2562 - val_accuracy: 0.9111\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2495 - accuracy: 0.9333 - val_loss: 0.2577 - val_accuracy: 0.9111\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2477 - accuracy: 0.9333 - val_loss: 0.2586 - val_accuracy: 0.9111\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2462 - accuracy: 0.9333 - val_loss: 0.2601 - val_accuracy: 0.9333\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.90 - 0s 11ms/step - loss: 0.2445 - accuracy: 0.9429 - val_loss: 0.2651 - val_accuracy: 0.9111\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2440 - accuracy: 0.9333 - val_loss: 0.2704 - val_accuracy: 0.9111\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2443 - accuracy: 0.9429 - val_loss: 0.2725 - val_accuracy: 0.9111\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2434 - accuracy: 0.9429 - val_loss: 0.2732 - val_accuracy: 0.9111\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2428 - accuracy: 0.9429 - val_loss: 0.2721 - val_accuracy: 0.9111\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2417 - accuracy: 0.9429 - val_loss: 0.2700 - val_accuracy: 0.9111\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2405 - accuracy: 0.9429 - val_loss: 0.2645 - val_accuracy: 0.9111\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2387 - accuracy: 0.9429 - val_loss: 0.2617 - val_accuracy: 0.9111\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2380 - accuracy: 0.9429 - val_loss: 0.2600 - val_accuracy: 0.9111\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2357 - accuracy: 0.9429 - val_loss: 0.2527 - val_accuracy: 0.9333\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2365 - accuracy: 0.9429 - val_loss: 0.2428 - val_accuracy: 0.9111\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2346 - accuracy: 0.9333 - val_loss: 0.2415 - val_accuracy: 0.9111\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2337 - accuracy: 0.9333 - val_loss: 0.2452 - val_accuracy: 0.9333\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2328 - accuracy: 0.9429 - val_loss: 0.2487 - val_accuracy: 0.9333\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2309 - accuracy: 0.9429 - val_loss: 0.2467 - val_accuracy: 0.9333\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2305 - accuracy: 0.9429 - val_loss: 0.2462 - val_accuracy: 0.9333\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2293 - accuracy: 0.9429 - val_loss: 0.2390 - val_accuracy: 0.9111\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2281 - accuracy: 0.9429 - val_loss: 0.2391 - val_accuracy: 0.9333\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2270 - accuracy: 0.9429 - val_loss: 0.2393 - val_accuracy: 0.9333\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2263 - accuracy: 0.9429 - val_loss: 0.2391 - val_accuracy: 0.9333\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2257 - accuracy: 0.9429 - val_loss: 0.2449 - val_accuracy: 0.9333\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2247 - accuracy: 0.9429 - val_loss: 0.2485 - val_accuracy: 0.9111\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2250 - accuracy: 0.9524 - val_loss: 0.2531 - val_accuracy: 0.9111\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2244 - accuracy: 0.9429 - val_loss: 0.2504 - val_accuracy: 0.9111\n",
      "Epoch 287/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2227 - accuracy: 0.9524 - val_loss: 0.2425 - val_accuracy: 0.9333\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2209 - accuracy: 0.9429 - val_loss: 0.2362 - val_accuracy: 0.9333\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2199 - accuracy: 0.9429 - val_loss: 0.2328 - val_accuracy: 0.9333\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2184 - accuracy: 0.9429 - val_loss: 0.2358 - val_accuracy: 0.9333\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2175 - accuracy: 0.9429 - val_loss: 0.2407 - val_accuracy: 0.9333\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2178 - accuracy: 0.9524 - val_loss: 0.2469 - val_accuracy: 0.9111\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2191 - accuracy: 0.9524 - val_loss: 0.2485 - val_accuracy: 0.9111\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2178 - accuracy: 0.9524 - val_loss: 0.2415 - val_accuracy: 0.9111\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2158 - accuracy: 0.9524 - val_loss: 0.2332 - val_accuracy: 0.9333\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2133 - accuracy: 0.9429 - val_loss: 0.2286 - val_accuracy: 0.9333\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2126 - accuracy: 0.9429 - val_loss: 0.2234 - val_accuracy: 0.9556\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2115 - accuracy: 0.9429 - val_loss: 0.2217 - val_accuracy: 0.9556\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2117 - accuracy: 0.9429 - val_loss: 0.2244 - val_accuracy: 0.9333\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2096 - accuracy: 0.9429 - val_loss: 0.2201 - val_accuracy: 0.9778\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2087 - accuracy: 0.9429 - val_loss: 0.2137 - val_accuracy: 0.9556\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2097 - accuracy: 0.9333 - val_loss: 0.2095 - val_accuracy: 0.9556\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2098 - accuracy: 0.9524 - val_loss: 0.2069 - val_accuracy: 0.9556\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2093 - accuracy: 0.9429 - val_loss: 0.2084 - val_accuracy: 0.9556\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2072 - accuracy: 0.9524 - val_loss: 0.2126 - val_accuracy: 0.9556\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2048 - accuracy: 0.9429 - val_loss: 0.2161 - val_accuracy: 0.9778\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2040 - accuracy: 0.9429 - val_loss: 0.2224 - val_accuracy: 0.9333\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2036 - accuracy: 0.9429 - val_loss: 0.2244 - val_accuracy: 0.9333\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2033 - accuracy: 0.9524 - val_loss: 0.2226 - val_accuracy: 0.9333\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2024 - accuracy: 0.9429 - val_loss: 0.2188 - val_accuracy: 0.9333\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2009 - accuracy: 0.9429 - val_loss: 0.2160 - val_accuracy: 0.9556\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2000 - accuracy: 0.9429 - val_loss: 0.2124 - val_accuracy: 0.9778\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1990 - accuracy: 0.9429 - val_loss: 0.2096 - val_accuracy: 0.9778\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1986 - accuracy: 0.9429 - val_loss: 0.2054 - val_accuracy: 0.9778\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1981 - accuracy: 0.9429 - val_loss: 0.2033 - val_accuracy: 0.9556\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1976 - accuracy: 0.9429 - val_loss: 0.2015 - val_accuracy: 0.9556\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1966 - accuracy: 0.9333 - val_loss: 0.2068 - val_accuracy: 0.9778\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1948 - accuracy: 0.9429 - val_loss: 0.2112 - val_accuracy: 0.9778\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1956 - accuracy: 0.9429 - val_loss: 0.2173 - val_accuracy: 0.9333\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1949 - accuracy: 0.9524 - val_loss: 0.2105 - val_accuracy: 0.9778\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1929 - accuracy: 0.9429 - val_loss: 0.2042 - val_accuracy: 0.9778\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1922 - accuracy: 0.9429 - val_loss: 0.1989 - val_accuracy: 0.9778\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1915 - accuracy: 0.9524 - val_loss: 0.1980 - val_accuracy: 0.9778\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1909 - accuracy: 0.9524 - val_loss: 0.1968 - val_accuracy: 0.9778\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1901 - accuracy: 0.9524 - val_loss: 0.1951 - val_accuracy: 0.9556\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1894 - accuracy: 0.9524 - val_loss: 0.1953 - val_accuracy: 0.9778\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1893 - accuracy: 0.9429 - val_loss: 0.1984 - val_accuracy: 0.9778\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1880 - accuracy: 0.9429 - val_loss: 0.1988 - val_accuracy: 0.9778\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1868 - accuracy: 0.9429 - val_loss: 0.1954 - val_accuracy: 0.9778\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1861 - accuracy: 0.9429 - val_loss: 0.1933 - val_accuracy: 0.9778\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1855 - accuracy: 0.9524 - val_loss: 0.1900 - val_accuracy: 0.9556\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1856 - accuracy: 0.9619 - val_loss: 0.1867 - val_accuracy: 0.9556\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1852 - accuracy: 0.9524 - val_loss: 0.1869 - val_accuracy: 0.9556\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1842 - accuracy: 0.9524 - val_loss: 0.1862 - val_accuracy: 0.9556\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1834 - accuracy: 0.9619 - val_loss: 0.1866 - val_accuracy: 0.9556\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1822 - accuracy: 0.9524 - val_loss: 0.1889 - val_accuracy: 0.9778\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1811 - accuracy: 0.9524 - val_loss: 0.1906 - val_accuracy: 0.9778\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1802 - accuracy: 0.9524 - val_loss: 0.1947 - val_accuracy: 0.9778\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1810 - accuracy: 0.9429 - val_loss: 0.2002 - val_accuracy: 0.9778\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1807 - accuracy: 0.9524 - val_loss: 0.1993 - val_accuracy: 0.9778\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1808 - accuracy: 0.9524 - val_loss: 0.1954 - val_accuracy: 0.9778\n",
      "Epoch 342/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1789 - accuracy: 0.9524 - val_loss: 0.1954 - val_accuracy: 0.9778\n",
      "Epoch 343/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1780 - accuracy: 0.9429 - val_loss: 0.1889 - val_accuracy: 0.9778\n",
      "Epoch 344/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1767 - accuracy: 0.9524 - val_loss: 0.1842 - val_accuracy: 0.9778\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1762 - accuracy: 0.9524 - val_loss: 0.1803 - val_accuracy: 0.9778\n",
      "Epoch 346/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1752 - accuracy: 0.9619 - val_loss: 0.1786 - val_accuracy: 0.9778\n",
      "Epoch 347/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1747 - accuracy: 0.9619 - val_loss: 0.1770 - val_accuracy: 0.9556\n",
      "Epoch 348/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1742 - accuracy: 0.9619 - val_loss: 0.1756 - val_accuracy: 0.9556\n",
      "Epoch 349/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1742 - accuracy: 0.9619 - val_loss: 0.1737 - val_accuracy: 0.9556\n",
      "Epoch 350/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1735 - accuracy: 0.9619 - val_loss: 0.1754 - val_accuracy: 0.9556\n",
      "Epoch 351/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1720 - accuracy: 0.9619 - val_loss: 0.1772 - val_accuracy: 0.9778\n",
      "Epoch 352/1000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.1715 - accuracy: 0.9524 - val_loss: 0.1798 - val_accuracy: 0.9778\n",
      "Epoch 353/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1699 - accuracy: 0.9524 - val_loss: 0.1884 - val_accuracy: 0.9778\n",
      "Epoch 354/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1715 - accuracy: 0.9524 - val_loss: 0.1914 - val_accuracy: 0.9778\n",
      "Epoch 355/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1720 - accuracy: 0.9524 - val_loss: 0.1906 - val_accuracy: 0.9778\n",
      "Epoch 356/1000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1703 - accuracy: 0.9524 - val_loss: 0.1810 - val_accuracy: 0.9778\n",
      "Epoch 357/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1679 - accuracy: 0.9524 - val_loss: 0.1728 - val_accuracy: 0.9778\n",
      "Epoch 358/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1691 - accuracy: 0.9619 - val_loss: 0.1686 - val_accuracy: 0.9556\n",
      "Epoch 359/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1669 - accuracy: 0.9619 - val_loss: 0.1718 - val_accuracy: 0.9778\n",
      "Epoch 360/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1666 - accuracy: 0.9524 - val_loss: 0.1755 - val_accuracy: 0.9778\n",
      "Epoch 361/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1658 - accuracy: 0.9524 - val_loss: 0.1738 - val_accuracy: 0.9778\n",
      "Epoch 362/1000\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1649 - accuracy: 0.9524 - val_loss: 0.1708 - val_accuracy: 0.9778\n",
      "Epoch 363/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1642 - accuracy: 0.9619 - val_loss: 0.1669 - val_accuracy: 0.9778\n",
      "Epoch 364/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1649 - accuracy: 0.9619 - val_loss: 0.1651 - val_accuracy: 0.9556\n",
      "Epoch 365/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1639 - accuracy: 0.9619 - val_loss: 0.1674 - val_accuracy: 0.9778\n",
      "Epoch 366/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1628 - accuracy: 0.9619 - val_loss: 0.1687 - val_accuracy: 0.9778\n",
      "Epoch 367/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1636 - accuracy: 0.9524 - val_loss: 0.1732 - val_accuracy: 0.9778\n",
      "Epoch 368/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1623 - accuracy: 0.9619 - val_loss: 0.1739 - val_accuracy: 0.9778\n",
      "Epoch 369/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1615 - accuracy: 0.9619 - val_loss: 0.1702 - val_accuracy: 0.9778\n",
      "Epoch 370/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1610 - accuracy: 0.9524 - val_loss: 0.1680 - val_accuracy: 0.9778\n",
      "Epoch 371/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1599 - accuracy: 0.9524 - val_loss: 0.1697 - val_accuracy: 0.9778\n",
      "Epoch 372/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1602 - accuracy: 0.9524 - val_loss: 0.1729 - val_accuracy: 0.9778\n",
      "Epoch 373/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1613 - accuracy: 0.9524 - val_loss: 0.1769 - val_accuracy: 0.9778\n",
      "Epoch 374/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1600 - accuracy: 0.9524 - val_loss: 0.1715 - val_accuracy: 0.9778\n",
      "Epoch 375/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1578 - accuracy: 0.9619 - val_loss: 0.1636 - val_accuracy: 0.9778\n",
      "Epoch 376/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1568 - accuracy: 0.9619 - val_loss: 0.1544 - val_accuracy: 0.9556\n",
      "Epoch 377/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1584 - accuracy: 0.9429 - val_loss: 0.1508 - val_accuracy: 0.9556\n",
      "Epoch 378/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1639 - accuracy: 0.9429 - val_loss: 0.1497 - val_accuracy: 0.9556\n",
      "Epoch 379/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1608 - accuracy: 0.9429 - val_loss: 0.1528 - val_accuracy: 0.9556\n",
      "Epoch 380/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1564 - accuracy: 0.9619 - val_loss: 0.1616 - val_accuracy: 0.9778\n",
      "Epoch 381/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1560 - accuracy: 0.9524 - val_loss: 0.1702 - val_accuracy: 0.9778\n",
      "Epoch 382/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1566 - accuracy: 0.9619 - val_loss: 0.1707 - val_accuracy: 0.9778\n",
      "Epoch 383/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1553 - accuracy: 0.9619 - val_loss: 0.1671 - val_accuracy: 0.9778\n",
      "Epoch 384/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1540 - accuracy: 0.9619 - val_loss: 0.1627 - val_accuracy: 0.9778\n",
      "Epoch 385/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1531 - accuracy: 0.9524 - val_loss: 0.1582 - val_accuracy: 0.9778\n",
      "Epoch 386/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1519 - accuracy: 0.9619 - val_loss: 0.1540 - val_accuracy: 0.9778\n",
      "Epoch 387/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1523 - accuracy: 0.9619 - val_loss: 0.1516 - val_accuracy: 0.9556\n",
      "Epoch 388/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1518 - accuracy: 0.9619 - val_loss: 0.1516 - val_accuracy: 0.9778\n",
      "Epoch 389/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1515 - accuracy: 0.9619 - val_loss: 0.1547 - val_accuracy: 0.9778\n",
      "Epoch 390/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1505 - accuracy: 0.9619 - val_loss: 0.1548 - val_accuracy: 0.9778\n",
      "Epoch 391/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1500 - accuracy: 0.9619 - val_loss: 0.1552 - val_accuracy: 0.9778\n",
      "Epoch 392/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1494 - accuracy: 0.9524 - val_loss: 0.1569 - val_accuracy: 0.9778\n",
      "Epoch 393/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1493 - accuracy: 0.9524 - val_loss: 0.1553 - val_accuracy: 0.9778\n",
      "Epoch 394/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1485 - accuracy: 0.9524 - val_loss: 0.1563 - val_accuracy: 0.9778\n",
      "Epoch 395/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1489 - accuracy: 0.9524 - val_loss: 0.1543 - val_accuracy: 0.9778\n",
      "Epoch 396/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1479 - accuracy: 0.9524 - val_loss: 0.1554 - val_accuracy: 0.9778\n",
      "Epoch 397/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1474 - accuracy: 0.9524 - val_loss: 0.1557 - val_accuracy: 0.9778\n",
      "Epoch 398/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1471 - accuracy: 0.9524 - val_loss: 0.1532 - val_accuracy: 0.9778\n",
      "Epoch 399/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1466 - accuracy: 0.9524 - val_loss: 0.1497 - val_accuracy: 0.9778\n",
      "Epoch 400/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1459 - accuracy: 0.9619 - val_loss: 0.1491 - val_accuracy: 0.9778\n",
      "Epoch 401/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1453 - accuracy: 0.9619 - val_loss: 0.1475 - val_accuracy: 0.9778\n",
      "Epoch 402/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1452 - accuracy: 0.9619 - val_loss: 0.1448 - val_accuracy: 0.9778\n",
      "Epoch 403/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1450 - accuracy: 0.9619 - val_loss: 0.1436 - val_accuracy: 0.9556\n",
      "Epoch 404/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1446 - accuracy: 0.9619 - val_loss: 0.1463 - val_accuracy: 0.9778\n",
      "Epoch 405/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1436 - accuracy: 0.9619 - val_loss: 0.1508 - val_accuracy: 0.9778\n",
      "Epoch 406/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1437 - accuracy: 0.9619 - val_loss: 0.1546 - val_accuracy: 0.9778\n",
      "Epoch 407/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1438 - accuracy: 0.9619 - val_loss: 0.1523 - val_accuracy: 0.9778\n",
      "Epoch 408/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1436 - accuracy: 0.9524 - val_loss: 0.1462 - val_accuracy: 0.9778\n",
      "Epoch 409/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1419 - accuracy: 0.9619 - val_loss: 0.1445 - val_accuracy: 0.9778\n",
      "Epoch 410/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1417 - accuracy: 0.9619 - val_loss: 0.1451 - val_accuracy: 0.9778\n",
      "Epoch 411/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1411 - accuracy: 0.9619 - val_loss: 0.1441 - val_accuracy: 0.9778\n",
      "Epoch 412/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1408 - accuracy: 0.9619 - val_loss: 0.1449 - val_accuracy: 0.9778\n",
      "Epoch 413/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1412 - accuracy: 0.9619 - val_loss: 0.1446 - val_accuracy: 0.9778\n",
      "Epoch 414/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1392 - accuracy: 0.9619 - val_loss: 0.1395 - val_accuracy: 0.9778\n",
      "Epoch 415/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1399 - accuracy: 0.9619 - val_loss: 0.1345 - val_accuracy: 0.9556\n",
      "Epoch 416/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1424 - accuracy: 0.9429 - val_loss: 0.1324 - val_accuracy: 0.9556\n",
      "Epoch 417/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1475 - accuracy: 0.9429 - val_loss: 0.1318 - val_accuracy: 0.9556\n",
      "Epoch 418/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1459 - accuracy: 0.9429 - val_loss: 0.1334 - val_accuracy: 0.9556\n",
      "Epoch 419/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1388 - accuracy: 0.9619 - val_loss: 0.1385 - val_accuracy: 0.9778\n",
      "Epoch 420/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1379 - accuracy: 0.9619 - val_loss: 0.1455 - val_accuracy: 0.9778\n",
      "Epoch 421/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1374 - accuracy: 0.9619 - val_loss: 0.1473 - val_accuracy: 0.9778\n",
      "Epoch 422/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1377 - accuracy: 0.9619 - val_loss: 0.1451 - val_accuracy: 0.9778\n",
      "Epoch 423/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1365 - accuracy: 0.9524 - val_loss: 0.1362 - val_accuracy: 0.9778\n",
      "Epoch 424/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1378 - accuracy: 0.9619 - val_loss: 0.1313 - val_accuracy: 0.9556\n",
      "Epoch 425/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1383 - accuracy: 0.9429 - val_loss: 0.1304 - val_accuracy: 0.9556\n",
      "Epoch 426/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1379 - accuracy: 0.9429 - val_loss: 0.1318 - val_accuracy: 0.9556\n",
      "Epoch 427/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1353 - accuracy: 0.9619 - val_loss: 0.1344 - val_accuracy: 0.9778\n",
      "Epoch 428/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1342 - accuracy: 0.9619 - val_loss: 0.1393 - val_accuracy: 0.9778\n",
      "Epoch 429/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1347 - accuracy: 0.9619 - val_loss: 0.1408 - val_accuracy: 0.9778\n",
      "Epoch 430/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1339 - accuracy: 0.9619 - val_loss: 0.1392 - val_accuracy: 0.9778\n",
      "Epoch 431/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1332 - accuracy: 0.9619 - val_loss: 0.1330 - val_accuracy: 0.9778\n",
      "Epoch 432/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1330 - accuracy: 0.9619 - val_loss: 0.1293 - val_accuracy: 0.9556\n",
      "Epoch 433/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1340 - accuracy: 0.9619 - val_loss: 0.1270 - val_accuracy: 0.9556\n",
      "Epoch 434/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1377 - accuracy: 0.9429 - val_loss: 0.1262 - val_accuracy: 0.9556\n",
      "Epoch 435/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1363 - accuracy: 0.9429 - val_loss: 0.1283 - val_accuracy: 0.9556\n",
      "Epoch 436/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1310 - accuracy: 0.9619 - val_loss: 0.1342 - val_accuracy: 0.9778\n",
      "Epoch 437/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1323 - accuracy: 0.9619 - val_loss: 0.1499 - val_accuracy: 0.9778\n",
      "Epoch 438/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1359 - accuracy: 0.9619 - val_loss: 0.1565 - val_accuracy: 0.9778\n",
      "Epoch 439/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1356 - accuracy: 0.9619 - val_loss: 0.1471 - val_accuracy: 0.9778\n",
      "Epoch 440/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1317 - accuracy: 0.9619 - val_loss: 0.1322 - val_accuracy: 0.9778\n",
      "Epoch 441/1000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1295 - accuracy: 0.9619 - val_loss: 0.1265 - val_accuracy: 0.9556\n",
      "Epoch 442/1000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1320 - accuracy: 0.9524 - val_loss: 0.1240 - val_accuracy: 0.9556\n",
      "Epoch 443/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1336 - accuracy: 0.9524 - val_loss: 0.1235 - val_accuracy: 0.9556\n",
      "Epoch 444/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1334 - accuracy: 0.9524 - val_loss: 0.1235 - val_accuracy: 0.9556\n",
      "Epoch 445/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1316 - accuracy: 0.9524 - val_loss: 0.1244 - val_accuracy: 0.9556\n",
      "Epoch 446/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1296 - accuracy: 0.9619 - val_loss: 0.1274 - val_accuracy: 0.9778\n",
      "Epoch 447/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1278 - accuracy: 0.9619 - val_loss: 0.1298 - val_accuracy: 0.9778\n",
      "Epoch 448/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1272 - accuracy: 0.9619 - val_loss: 0.1298 - val_accuracy: 0.9778\n",
      "Epoch 449/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1267 - accuracy: 0.9619 - val_loss: 0.1277 - val_accuracy: 0.9778\n",
      "Epoch 450/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1264 - accuracy: 0.9619 - val_loss: 0.1264 - val_accuracy: 0.9778\n",
      "Epoch 451/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1264 - accuracy: 0.9619 - val_loss: 0.1254 - val_accuracy: 0.9778\n",
      "Epoch 452/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1260 - accuracy: 0.9619 - val_loss: 0.1261 - val_accuracy: 0.9778\n",
      "Epoch 453/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1254 - accuracy: 0.9619 - val_loss: 0.1277 - val_accuracy: 0.9778\n",
      "Epoch 454/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1255 - accuracy: 0.9619 - val_loss: 0.1290 - val_accuracy: 0.9778\n",
      "Epoch 455/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1249 - accuracy: 0.9619 - val_loss: 0.1294 - val_accuracy: 0.9778\n",
      "Epoch 456/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1247 - accuracy: 0.9619 - val_loss: 0.1281 - val_accuracy: 0.9778\n",
      "Epoch 457/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1251 - accuracy: 0.9619 - val_loss: 0.1271 - val_accuracy: 0.9778\n",
      "Epoch 458/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1243 - accuracy: 0.9619 - val_loss: 0.1274 - val_accuracy: 0.9778\n",
      "Epoch 459/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1237 - accuracy: 0.9619 - val_loss: 0.1261 - val_accuracy: 0.9778\n",
      "Epoch 460/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1237 - accuracy: 0.9619 - val_loss: 0.1263 - val_accuracy: 0.9778\n",
      "Epoch 461/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1228 - accuracy: 0.9714 - val_loss: 0.1292 - val_accuracy: 0.9778\n",
      "Epoch 462/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1253 - accuracy: 0.9619 - val_loss: 0.1308 - val_accuracy: 0.9778\n",
      "Epoch 463/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1223 - accuracy: 0.9714 - val_loss: 0.1253 - val_accuracy: 0.9778\n",
      "Epoch 464/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1227 - accuracy: 0.9619 - val_loss: 0.1209 - val_accuracy: 0.9778\n",
      "Epoch 465/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1224 - accuracy: 0.9619 - val_loss: 0.1200 - val_accuracy: 0.9778\n",
      "Epoch 466/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1224 - accuracy: 0.9619 - val_loss: 0.1186 - val_accuracy: 0.9556\n",
      "Epoch 467/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1230 - accuracy: 0.9619 - val_loss: 0.1192 - val_accuracy: 0.9778\n",
      "Epoch 468/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1226 - accuracy: 0.9619 - val_loss: 0.1207 - val_accuracy: 0.9778\n",
      "Epoch 469/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1210 - accuracy: 0.9619 - val_loss: 0.1196 - val_accuracy: 0.9778\n",
      "Epoch 470/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1207 - accuracy: 0.9619 - val_loss: 0.1201 - val_accuracy: 0.9778\n",
      "Epoch 471/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1202 - accuracy: 0.9619 - val_loss: 0.1216 - val_accuracy: 0.9778\n",
      "Epoch 472/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1197 - accuracy: 0.9619 - val_loss: 0.1246 - val_accuracy: 0.9778\n",
      "Epoch 473/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1212 - accuracy: 0.9714 - val_loss: 0.1289 - val_accuracy: 0.9778\n",
      "Epoch 474/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1205 - accuracy: 0.9619 - val_loss: 0.1286 - val_accuracy: 0.9778\n",
      "Epoch 475/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1203 - accuracy: 0.9619 - val_loss: 0.1281 - val_accuracy: 0.9778\n",
      "Epoch 476/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1202 - accuracy: 0.9714 - val_loss: 0.1246 - val_accuracy: 0.9778\n",
      "Epoch 477/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1189 - accuracy: 0.9714 - val_loss: 0.1232 - val_accuracy: 0.9778\n",
      "Epoch 478/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1185 - accuracy: 0.9714 - val_loss: 0.1246 - val_accuracy: 0.9778\n",
      "Epoch 479/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1185 - accuracy: 0.9714 - val_loss: 0.1250 - val_accuracy: 0.9778\n",
      "Epoch 480/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1186 - accuracy: 0.9714 - val_loss: 0.1206 - val_accuracy: 0.9778\n",
      "Epoch 481/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1172 - accuracy: 0.9619 - val_loss: 0.1189 - val_accuracy: 0.9778\n",
      "Epoch 482/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1167 - accuracy: 0.9619 - val_loss: 0.1167 - val_accuracy: 0.9778\n",
      "Epoch 483/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1182 - accuracy: 0.9619 - val_loss: 0.1143 - val_accuracy: 0.9556\n",
      "Epoch 484/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1171 - accuracy: 0.9619 - val_loss: 0.1163 - val_accuracy: 0.9778\n",
      "Epoch 485/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1161 - accuracy: 0.9619 - val_loss: 0.1205 - val_accuracy: 0.9778\n",
      "Epoch 486/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1172 - accuracy: 0.9714 - val_loss: 0.1235 - val_accuracy: 0.9778\n",
      "Epoch 487/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1163 - accuracy: 0.9714 - val_loss: 0.1211 - val_accuracy: 0.9778\n",
      "Epoch 488/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1164 - accuracy: 0.9714 - val_loss: 0.1175 - val_accuracy: 0.9778\n",
      "Epoch 489/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1152 - accuracy: 0.9619 - val_loss: 0.1166 - val_accuracy: 0.9778\n",
      "Epoch 490/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1157 - accuracy: 0.9619 - val_loss: 0.1141 - val_accuracy: 0.9778\n",
      "Epoch 491/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1153 - accuracy: 0.9619 - val_loss: 0.1147 - val_accuracy: 0.9778\n",
      "Epoch 492/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1146 - accuracy: 0.9619 - val_loss: 0.1147 - val_accuracy: 0.9778\n",
      "Epoch 493/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1143 - accuracy: 0.9619 - val_loss: 0.1168 - val_accuracy: 0.9778\n",
      "Epoch 494/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 0.1173 - val_accuracy: 0.9778\n",
      "Epoch 495/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1136 - accuracy: 0.9714 - val_loss: 0.1178 - val_accuracy: 0.9778\n",
      "Epoch 496/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1136 - accuracy: 0.9714 - val_loss: 0.1168 - val_accuracy: 0.9778\n",
      "Epoch 497/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1131 - accuracy: 0.9714 - val_loss: 0.1158 - val_accuracy: 0.9778\n",
      "Epoch 498/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1128 - accuracy: 0.9619 - val_loss: 0.1143 - val_accuracy: 0.9778\n",
      "Epoch 499/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 0.1120 - val_accuracy: 0.9778\n",
      "Epoch 500/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1132 - accuracy: 0.9619 - val_loss: 0.1136 - val_accuracy: 0.9778\n",
      "Epoch 501/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1122 - accuracy: 0.9619 - val_loss: 0.1139 - val_accuracy: 0.9778\n",
      "Epoch 502/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1120 - accuracy: 0.9714 - val_loss: 0.1151 - val_accuracy: 0.9778\n",
      "Epoch 503/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1119 - accuracy: 0.9619 - val_loss: 0.1149 - val_accuracy: 0.9778\n",
      "Epoch 504/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1116 - accuracy: 0.9714 - val_loss: 0.1180 - val_accuracy: 0.9778\n",
      "Epoch 505/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1120 - accuracy: 0.9714 - val_loss: 0.1205 - val_accuracy: 0.9778\n",
      "Epoch 506/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1124 - accuracy: 0.9714 - val_loss: 0.1215 - val_accuracy: 0.9778\n",
      "Epoch 507/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1124 - accuracy: 0.9619 - val_loss: 0.1208 - val_accuracy: 0.9778\n",
      "Epoch 508/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1125 - accuracy: 0.9619 - val_loss: 0.1161 - val_accuracy: 0.9778\n",
      "Epoch 509/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1104 - accuracy: 0.9714 - val_loss: 0.1144 - val_accuracy: 0.9778\n",
      "Epoch 510/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1099 - accuracy: 0.9714 - val_loss: 0.1127 - val_accuracy: 0.9778\n",
      "Epoch 511/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1096 - accuracy: 0.9619 - val_loss: 0.1107 - val_accuracy: 0.9778\n",
      "Epoch 512/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1100 - accuracy: 0.9714 - val_loss: 0.1075 - val_accuracy: 0.9778\n",
      "Epoch 513/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1101 - accuracy: 0.9714 - val_loss: 0.1063 - val_accuracy: 0.9556\n",
      "Epoch 514/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1124 - accuracy: 0.9619 - val_loss: 0.1057 - val_accuracy: 0.9556\n",
      "Epoch 515/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1119 - accuracy: 0.9619 - val_loss: 0.1053 - val_accuracy: 0.9556\n",
      "Epoch 516/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1126 - accuracy: 0.9524 - val_loss: 0.1051 - val_accuracy: 0.9556\n",
      "Epoch 517/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1116 - accuracy: 0.9619 - val_loss: 0.1058 - val_accuracy: 0.9556\n",
      "Epoch 518/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1091 - accuracy: 0.9714 - val_loss: 0.1092 - val_accuracy: 0.9778\n",
      "Epoch 519/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1067 - accuracy: 0.9714 - val_loss: 0.1173 - val_accuracy: 0.9778\n",
      "Epoch 520/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1099 - accuracy: 0.9619 - val_loss: 0.1248 - val_accuracy: 0.9778\n",
      "Epoch 521/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1141 - accuracy: 0.9619 - val_loss: 0.1270 - val_accuracy: 0.9778\n",
      "Epoch 522/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1118 - accuracy: 0.9619 - val_loss: 0.1205 - val_accuracy: 0.9778\n",
      "Epoch 523/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1089 - accuracy: 0.9714 - val_loss: 0.1116 - val_accuracy: 0.9778\n",
      "Epoch 524/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1091 - accuracy: 0.9714 - val_loss: 0.1070 - val_accuracy: 0.9778\n",
      "Epoch 525/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1066 - accuracy: 0.9714 - val_loss: 0.1069 - val_accuracy: 0.9778\n",
      "Epoch 526/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1070 - accuracy: 0.9714 - val_loss: 0.1077 - val_accuracy: 0.9778\n",
      "Epoch 527/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1064 - accuracy: 0.9714 - val_loss: 0.1081 - val_accuracy: 0.9778\n",
      "Epoch 528/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1058 - accuracy: 0.9714 - val_loss: 0.1080 - val_accuracy: 0.9778\n",
      "Epoch 529/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1056 - accuracy: 0.9810 - val_loss: 0.1081 - val_accuracy: 0.9778\n",
      "Epoch 530/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1054 - accuracy: 0.9714 - val_loss: 0.1083 - val_accuracy: 0.9778\n",
      "Epoch 531/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1053 - accuracy: 0.9714 - val_loss: 0.1109 - val_accuracy: 0.9778\n",
      "Epoch 532/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1062 - accuracy: 0.9714 - val_loss: 0.1127 - val_accuracy: 0.9778\n",
      "Epoch 533/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1058 - accuracy: 0.9714 - val_loss: 0.1114 - val_accuracy: 0.9778\n",
      "Epoch 534/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1045 - accuracy: 0.9714 - val_loss: 0.1073 - val_accuracy: 0.9778\n",
      "Epoch 535/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1063 - accuracy: 0.9714 - val_loss: 0.1022 - val_accuracy: 0.9556\n",
      "Epoch 536/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1065 - accuracy: 0.9714 - val_loss: 0.1017 - val_accuracy: 0.9556\n",
      "Epoch 537/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1063 - accuracy: 0.9714 - val_loss: 0.1017 - val_accuracy: 0.9556\n",
      "Epoch 538/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1056 - accuracy: 0.9714 - val_loss: 0.1021 - val_accuracy: 0.9778\n",
      "Epoch 539/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0942 - accuracy: 0.96 - 0s 14ms/step - loss: 0.1045 - accuracy: 0.9714 - val_loss: 0.1034 - val_accuracy: 0.9778\n",
      "Epoch 540/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1037 - accuracy: 0.9714 - val_loss: 0.1048 - val_accuracy: 0.9778\n",
      "Epoch 541/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1030 - accuracy: 0.9714 - val_loss: 0.1058 - val_accuracy: 0.9778\n",
      "Epoch 542/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1032 - accuracy: 0.9810 - val_loss: 0.1059 - val_accuracy: 0.9778\n",
      "Epoch 543/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1044 - accuracy: 0.9810 - val_loss: 0.1030 - val_accuracy: 0.9778\n",
      "Epoch 544/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1027 - accuracy: 0.9714 - val_loss: 0.1033 - val_accuracy: 0.9778\n",
      "Epoch 545/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1021 - accuracy: 0.9714 - val_loss: 0.1047 - val_accuracy: 0.9778\n",
      "Epoch 546/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1030 - accuracy: 0.9810 - val_loss: 0.1071 - val_accuracy: 0.9778\n",
      "Epoch 547/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1025 - accuracy: 0.9810 - val_loss: 0.1082 - val_accuracy: 0.9778\n",
      "Epoch 548/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1023 - accuracy: 0.9810 - val_loss: 0.1072 - val_accuracy: 0.9778\n",
      "Epoch 549/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1021 - accuracy: 0.9810 - val_loss: 0.1062 - val_accuracy: 0.9778\n",
      "Epoch 550/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1016 - accuracy: 0.9810 - val_loss: 0.1063 - val_accuracy: 0.9778\n",
      "Epoch 551/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1015 - accuracy: 0.9810 - val_loss: 0.1066 - val_accuracy: 0.9778\n",
      "Epoch 552/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1014 - accuracy: 0.9810 - val_loss: 0.1079 - val_accuracy: 0.9778\n",
      "Epoch 553/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1014 - accuracy: 0.9810 - val_loss: 0.1066 - val_accuracy: 0.9778\n",
      "Epoch 554/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1012 - accuracy: 0.9810 - val_loss: 0.1068 - val_accuracy: 0.9778\n",
      "Epoch 555/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1010 - accuracy: 0.9810 - val_loss: 0.1067 - val_accuracy: 0.9778\n",
      "Epoch 556/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1009 - accuracy: 0.9810 - val_loss: 0.1088 - val_accuracy: 0.9778\n",
      "Epoch 557/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1014 - accuracy: 0.9714 - val_loss: 0.1098 - val_accuracy: 0.9778\n",
      "Epoch 558/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1010 - accuracy: 0.9810 - val_loss: 0.1064 - val_accuracy: 0.9778\n",
      "Epoch 559/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0999 - accuracy: 0.9810 - val_loss: 0.1026 - val_accuracy: 0.9778\n",
      "Epoch 560/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0999 - accuracy: 0.9810 - val_loss: 0.0996 - val_accuracy: 0.9778\n",
      "Epoch 561/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0997 - accuracy: 0.9714 - val_loss: 0.0989 - val_accuracy: 0.9778\n",
      "Epoch 562/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0999 - accuracy: 0.9714 - val_loss: 0.0998 - val_accuracy: 0.9778\n",
      "Epoch 563/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0993 - accuracy: 0.9714 - val_loss: 0.1012 - val_accuracy: 0.9778\n",
      "Epoch 564/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0987 - accuracy: 0.9810 - val_loss: 0.1019 - val_accuracy: 0.9778\n",
      "Epoch 565/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0992 - accuracy: 0.9810 - val_loss: 0.1039 - val_accuracy: 0.9778\n",
      "Epoch 566/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0989 - accuracy: 0.9810 - val_loss: 0.1043 - val_accuracy: 0.9778\n",
      "Epoch 567/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0985 - accuracy: 0.9810 - val_loss: 0.1069 - val_accuracy: 0.9778\n",
      "Epoch 568/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1005 - accuracy: 0.9714 - val_loss: 0.1086 - val_accuracy: 0.9778\n",
      "Epoch 569/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0995 - accuracy: 0.9810 - val_loss: 0.1030 - val_accuracy: 0.9778\n",
      "Epoch 570/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0982 - accuracy: 0.9810 - val_loss: 0.1019 - val_accuracy: 0.9778\n",
      "Epoch 571/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0973 - accuracy: 0.9810 - val_loss: 0.1002 - val_accuracy: 0.9778\n",
      "Epoch 572/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0969 - accuracy: 0.9810 - val_loss: 0.0983 - val_accuracy: 0.9778\n",
      "Epoch 573/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0982 - accuracy: 0.9714 - val_loss: 0.0964 - val_accuracy: 0.9778\n",
      "Epoch 574/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0983 - accuracy: 0.9714 - val_loss: 0.0973 - val_accuracy: 0.9778\n",
      "Epoch 575/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0967 - accuracy: 0.9714 - val_loss: 0.0991 - val_accuracy: 0.9778\n",
      "Epoch 576/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0965 - accuracy: 0.9810 - val_loss: 0.1013 - val_accuracy: 0.9778\n",
      "Epoch 577/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0966 - accuracy: 0.9810 - val_loss: 0.1024 - val_accuracy: 0.9778\n",
      "Epoch 578/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0965 - accuracy: 0.9810 - val_loss: 0.1011 - val_accuracy: 0.9778\n",
      "Epoch 579/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0964 - accuracy: 0.9810 - val_loss: 0.0993 - val_accuracy: 0.9778\n",
      "Epoch 580/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0958 - accuracy: 0.9810 - val_loss: 0.0988 - val_accuracy: 0.9778\n",
      "Epoch 581/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0959 - accuracy: 0.9810 - val_loss: 0.0994 - val_accuracy: 0.9778\n",
      "Epoch 582/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0956 - accuracy: 0.9810 - val_loss: 0.1004 - val_accuracy: 0.9778\n",
      "Epoch 583/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0958 - accuracy: 0.9810 - val_loss: 0.1013 - val_accuracy: 0.9778\n",
      "Epoch 584/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0957 - accuracy: 0.9810 - val_loss: 0.1001 - val_accuracy: 0.9778\n",
      "Epoch 585/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0954 - accuracy: 0.9810 - val_loss: 0.0999 - val_accuracy: 0.9778\n",
      "Epoch 586/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0954 - accuracy: 0.9810 - val_loss: 0.0989 - val_accuracy: 0.9778\n",
      "Epoch 587/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0951 - accuracy: 0.9810 - val_loss: 0.1009 - val_accuracy: 0.9778\n",
      "Epoch 588/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0960 - accuracy: 0.9810 - val_loss: 0.1022 - val_accuracy: 0.9778\n",
      "Epoch 589/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0954 - accuracy: 0.9810 - val_loss: 0.0970 - val_accuracy: 0.9778\n",
      "Epoch 590/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0941 - accuracy: 0.9714 - val_loss: 0.0946 - val_accuracy: 0.9778\n",
      "Epoch 591/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0972 - accuracy: 0.9619 - val_loss: 0.0938 - val_accuracy: 0.9778\n",
      "Epoch 592/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0953 - accuracy: 0.9714 - val_loss: 0.0947 - val_accuracy: 0.9778\n",
      "Epoch 593/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0965 - accuracy: 0.9714 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
      "Epoch 594/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0936 - accuracy: 0.9810 - val_loss: 0.0973 - val_accuracy: 0.9778\n",
      "Epoch 595/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0933 - accuracy: 0.9810 - val_loss: 0.0979 - val_accuracy: 0.9778\n",
      "Epoch 596/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0933 - accuracy: 0.9810 - val_loss: 0.0977 - val_accuracy: 0.9778\n",
      "Epoch 597/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0934 - accuracy: 0.9810 - val_loss: 0.0962 - val_accuracy: 0.9778\n",
      "Epoch 598/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0932 - accuracy: 0.9810 - val_loss: 0.0958 - val_accuracy: 0.9778\n",
      "Epoch 599/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0927 - accuracy: 0.9810 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
      "Epoch 600/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0927 - accuracy: 0.9810 - val_loss: 0.0979 - val_accuracy: 0.9778\n",
      "Epoch 601/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0926 - accuracy: 0.9810 - val_loss: 0.0970 - val_accuracy: 0.9778\n",
      "Epoch 602/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0931 - accuracy: 0.9810 - val_loss: 0.0976 - val_accuracy: 0.9778\n",
      "Epoch 603/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0922 - accuracy: 0.9810 - val_loss: 0.0963 - val_accuracy: 0.9778\n",
      "Epoch 604/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0926 - accuracy: 0.9810 - val_loss: 0.0933 - val_accuracy: 0.9778\n",
      "Epoch 605/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0923 - accuracy: 0.9714 - val_loss: 0.0926 - val_accuracy: 0.9778\n",
      "Epoch 606/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0931 - accuracy: 0.9714 - val_loss: 0.0925 - val_accuracy: 0.9778\n",
      "Epoch 607/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0913 - accuracy: 0.9714 - val_loss: 0.0948 - val_accuracy: 0.9778\n",
      "Epoch 608/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0935 - accuracy: 0.9810 - val_loss: 0.1003 - val_accuracy: 0.9778\n",
      "Epoch 609/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0924 - accuracy: 0.9810 - val_loss: 0.1018 - val_accuracy: 0.9778\n",
      "Epoch 610/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0935 - accuracy: 0.9810 - val_loss: 0.1013 - val_accuracy: 0.9778\n",
      "Epoch 611/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0921 - accuracy: 0.9810 - val_loss: 0.0944 - val_accuracy: 0.9778\n",
      "Epoch 612/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0904 - accuracy: 0.9810 - val_loss: 0.0920 - val_accuracy: 0.9778\n",
      "Epoch 613/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0912 - accuracy: 0.9714 - val_loss: 0.0915 - val_accuracy: 0.9778\n",
      "Epoch 614/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0914 - accuracy: 0.9714 - val_loss: 0.0919 - val_accuracy: 0.9778\n",
      "Epoch 615/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0903 - accuracy: 0.9714 - val_loss: 0.0940 - val_accuracy: 0.9778\n",
      "Epoch 616/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0895 - accuracy: 0.9810 - val_loss: 0.0975 - val_accuracy: 0.9778\n",
      "Epoch 617/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0915 - accuracy: 0.9810 - val_loss: 0.1020 - val_accuracy: 0.9778\n",
      "Epoch 618/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0918 - accuracy: 0.9810 - val_loss: 0.0991 - val_accuracy: 0.9778\n",
      "Epoch 619/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0907 - accuracy: 0.9810 - val_loss: 0.0950 - val_accuracy: 0.9778\n",
      "Epoch 620/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0907 - accuracy: 0.9810 - val_loss: 0.0933 - val_accuracy: 0.9778\n",
      "Epoch 621/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0903 - accuracy: 0.9810 - val_loss: 0.0946 - val_accuracy: 0.9778\n",
      "Epoch 622/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0894 - accuracy: 0.9810 - val_loss: 0.0949 - val_accuracy: 0.9778\n",
      "Epoch 623/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0894 - accuracy: 0.9810 - val_loss: 0.0952 - val_accuracy: 0.9778\n",
      "Epoch 624/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0896 - accuracy: 0.9810 - val_loss: 0.0975 - val_accuracy: 0.9778\n",
      "Epoch 625/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0909 - accuracy: 0.9810 - val_loss: 0.0976 - val_accuracy: 0.9778\n",
      "Epoch 626/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0901 - accuracy: 0.9810 - val_loss: 0.0924 - val_accuracy: 0.9778\n",
      "Epoch 627/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0888 - accuracy: 0.9810 - val_loss: 0.0924 - val_accuracy: 0.9778\n",
      "Epoch 628/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0884 - accuracy: 0.9810 - val_loss: 0.0939 - val_accuracy: 0.9778\n",
      "Epoch 629/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0884 - accuracy: 0.9810 - val_loss: 0.0945 - val_accuracy: 0.9778\n",
      "Epoch 630/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0884 - accuracy: 0.9810 - val_loss: 0.0946 - val_accuracy: 0.9778\n",
      "Epoch 631/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.0936 - val_accuracy: 0.9778\n",
      "Epoch 632/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.0952 - val_accuracy: 0.9778\n",
      "Epoch 633/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0892 - accuracy: 0.9810 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
      "Epoch 634/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.0963 - val_accuracy: 0.9778\n",
      "Epoch 635/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0883 - accuracy: 0.9810 - val_loss: 0.0952 - val_accuracy: 0.9778\n",
      "Epoch 636/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0876 - accuracy: 0.9810 - val_loss: 0.0937 - val_accuracy: 0.9778\n",
      "Epoch 637/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0874 - accuracy: 0.9810 - val_loss: 0.0921 - val_accuracy: 0.9778\n",
      "Epoch 638/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0871 - accuracy: 0.9810 - val_loss: 0.0921 - val_accuracy: 0.9778\n",
      "Epoch 639/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0877 - accuracy: 0.9810 - val_loss: 0.0902 - val_accuracy: 0.9778\n",
      "Epoch 640/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0875 - accuracy: 0.9714 - val_loss: 0.0896 - val_accuracy: 0.9778\n",
      "Epoch 641/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0868 - accuracy: 0.9714 - val_loss: 0.0903 - val_accuracy: 0.9778\n",
      "Epoch 642/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0864 - accuracy: 0.9810 - val_loss: 0.0937 - val_accuracy: 0.9778\n",
      "Epoch 643/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0867 - accuracy: 0.9810 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
      "Epoch 644/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0879 - accuracy: 0.9810 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
      "Epoch 645/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.0981 - val_accuracy: 0.9778\n",
      "Epoch 646/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0877 - accuracy: 0.9810 - val_loss: 0.0953 - val_accuracy: 0.9778\n",
      "Epoch 647/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0866 - accuracy: 0.9810 - val_loss: 0.0925 - val_accuracy: 0.9778\n",
      "Epoch 648/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0857 - accuracy: 0.9810 - val_loss: 0.0907 - val_accuracy: 0.9778\n",
      "Epoch 649/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0855 - accuracy: 0.9810 - val_loss: 0.0899 - val_accuracy: 0.9778\n",
      "Epoch 650/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0855 - accuracy: 0.9810 - val_loss: 0.0900 - val_accuracy: 0.9778\n",
      "Epoch 651/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0853 - accuracy: 0.9810 - val_loss: 0.0908 - val_accuracy: 0.9778\n",
      "Epoch 652/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0859 - accuracy: 0.9810 - val_loss: 0.0925 - val_accuracy: 0.9778\n",
      "Epoch 653/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0855 - accuracy: 0.9810 - val_loss: 0.0929 - val_accuracy: 0.9778\n",
      "Epoch 654/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0855 - accuracy: 0.9810 - val_loss: 0.0936 - val_accuracy: 0.9778\n",
      "Epoch 655/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0862 - accuracy: 0.9810 - val_loss: 0.0965 - val_accuracy: 0.9778\n",
      "Epoch 656/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0866 - accuracy: 0.9810 - val_loss: 0.0959 - val_accuracy: 0.9778\n",
      "Epoch 657/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0862 - accuracy: 0.9810 - val_loss: 0.0946 - val_accuracy: 0.9778\n",
      "Epoch 658/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0856 - accuracy: 0.9810 - val_loss: 0.0942 - val_accuracy: 0.9778\n",
      "Epoch 659/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0853 - accuracy: 0.9810 - val_loss: 0.0932 - val_accuracy: 0.9778\n",
      "Epoch 660/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0849 - accuracy: 0.9810 - val_loss: 0.0921 - val_accuracy: 0.9778\n",
      "Epoch 661/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0843 - accuracy: 0.9810 - val_loss: 0.0905 - val_accuracy: 0.9778\n",
      "Epoch 662/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0846 - accuracy: 0.9810 - val_loss: 0.0889 - val_accuracy: 0.9778\n",
      "Epoch 663/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0840 - accuracy: 0.9810 - val_loss: 0.0897 - val_accuracy: 0.9778\n",
      "Epoch 664/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0863 - accuracy: 0.9810 - val_loss: 0.0955 - val_accuracy: 0.9778\n",
      "Epoch 665/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0855 - accuracy: 0.9810 - val_loss: 0.0970 - val_accuracy: 0.9778\n",
      "Epoch 666/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0862 - accuracy: 0.9810 - val_loss: 0.0980 - val_accuracy: 0.9778\n",
      "Epoch 667/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0860 - accuracy: 0.9810 - val_loss: 0.0949 - val_accuracy: 0.9778\n",
      "Epoch 668/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0846 - accuracy: 0.9810 - val_loss: 0.0915 - val_accuracy: 0.9778\n",
      "Epoch 669/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0831 - accuracy: 0.9810 - val_loss: 0.0884 - val_accuracy: 0.9778\n",
      "Epoch 670/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0843 - accuracy: 0.9810 - val_loss: 0.0869 - val_accuracy: 0.9778\n",
      "Epoch 671/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0832 - accuracy: 0.9810 - val_loss: 0.0880 - val_accuracy: 0.9778\n",
      "Epoch 672/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0828 - accuracy: 0.9810 - val_loss: 0.0893 - val_accuracy: 0.9778\n",
      "Epoch 673/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0826 - accuracy: 0.9810 - val_loss: 0.0906 - val_accuracy: 0.9778\n",
      "Epoch 674/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0839 - accuracy: 0.9810 - val_loss: 0.0938 - val_accuracy: 0.9778\n",
      "Epoch 675/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0836 - accuracy: 0.9810 - val_loss: 0.0919 - val_accuracy: 0.9778\n",
      "Epoch 676/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0828 - accuracy: 0.9810 - val_loss: 0.0878 - val_accuracy: 0.9778\n",
      "Epoch 677/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 1.00 - 0s 15ms/step - loss: 0.0820 - accuracy: 0.9810 - val_loss: 0.0857 - val_accuracy: 0.9778\n",
      "Epoch 678/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0828 - accuracy: 0.9619 - val_loss: 0.0858 - val_accuracy: 0.9778\n",
      "Epoch 679/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0822 - accuracy: 0.9714 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
      "Epoch 680/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0823 - accuracy: 0.9810 - val_loss: 0.0868 - val_accuracy: 0.9778\n",
      "Epoch 681/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0821 - accuracy: 0.9810 - val_loss: 0.0885 - val_accuracy: 0.9778\n",
      "Epoch 682/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0816 - accuracy: 0.9810 - val_loss: 0.0901 - val_accuracy: 0.9778\n",
      "Epoch 683/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0858 - accuracy: 0.9810 - val_loss: 0.0947 - val_accuracy: 0.9778\n",
      "Epoch 684/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0830 - accuracy: 0.9810 - val_loss: 0.0883 - val_accuracy: 0.9778\n",
      "Epoch 685/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0805 - accuracy: 0.9810 - val_loss: 0.0854 - val_accuracy: 0.9778\n",
      "Epoch 686/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0817 - accuracy: 0.9714 - val_loss: 0.0841 - val_accuracy: 0.9778\n",
      "Epoch 687/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0833 - accuracy: 0.9619 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
      "Epoch 688/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0816 - accuracy: 0.9619 - val_loss: 0.0859 - val_accuracy: 0.9778\n",
      "Epoch 689/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0804 - accuracy: 0.9810 - val_loss: 0.0899 - val_accuracy: 0.9778\n",
      "Epoch 690/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0818 - accuracy: 0.9810 - val_loss: 0.0919 - val_accuracy: 0.9778\n",
      "Epoch 691/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0833 - accuracy: 0.9810 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
      "Epoch 692/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0806 - accuracy: 0.9810 - val_loss: 0.0881 - val_accuracy: 0.9778\n",
      "Epoch 693/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0803 - accuracy: 0.9810 - val_loss: 0.0878 - val_accuracy: 0.9778\n",
      "Epoch 694/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0804 - accuracy: 0.9810 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
      "Epoch 695/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0803 - accuracy: 0.9810 - val_loss: 0.0895 - val_accuracy: 0.9778\n",
      "Epoch 696/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0806 - accuracy: 0.9810 - val_loss: 0.0899 - val_accuracy: 0.9778\n",
      "Epoch 697/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0804 - accuracy: 0.9810 - val_loss: 0.0890 - val_accuracy: 0.9778\n",
      "Epoch 698/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0800 - accuracy: 0.9810 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
      "Epoch 699/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0801 - accuracy: 0.9810 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 700/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0794 - accuracy: 0.9810 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
      "Epoch 701/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0796 - accuracy: 0.9810 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 702/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0793 - accuracy: 0.9810 - val_loss: 0.0870 - val_accuracy: 0.9778\n",
      "Epoch 703/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0794 - accuracy: 0.9810 - val_loss: 0.0876 - val_accuracy: 0.9778\n",
      "Epoch 704/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0795 - accuracy: 0.9810 - val_loss: 0.0880 - val_accuracy: 0.9778\n",
      "Epoch 705/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0804 - accuracy: 0.9810 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
      "Epoch 706/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0808 - accuracy: 0.9810 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 707/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0791 - accuracy: 0.9810 - val_loss: 0.0859 - val_accuracy: 0.9778\n",
      "Epoch 708/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0785 - accuracy: 0.9810 - val_loss: 0.0870 - val_accuracy: 0.9778\n",
      "Epoch 709/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0790 - accuracy: 0.9810 - val_loss: 0.0869 - val_accuracy: 0.9778\n",
      "Epoch 710/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0791 - accuracy: 0.9810 - val_loss: 0.0871 - val_accuracy: 0.9778\n",
      "Epoch 711/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0784 - accuracy: 0.9810 - val_loss: 0.0852 - val_accuracy: 0.9778\n",
      "Epoch 712/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0782 - accuracy: 0.9810 - val_loss: 0.0854 - val_accuracy: 0.9778\n",
      "Epoch 713/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0786 - accuracy: 0.9810 - val_loss: 0.0855 - val_accuracy: 0.9778\n",
      "Epoch 714/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0782 - accuracy: 0.9810 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
      "Epoch 715/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0785 - accuracy: 0.9810 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 716/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0786 - accuracy: 0.9810 - val_loss: 0.0875 - val_accuracy: 0.9778\n",
      "Epoch 717/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0781 - accuracy: 0.9810 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
      "Epoch 718/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0776 - accuracy: 0.9810 - val_loss: 0.0852 - val_accuracy: 0.9778\n",
      "Epoch 719/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0776 - accuracy: 0.9810 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 720/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0780 - accuracy: 0.9810 - val_loss: 0.0850 - val_accuracy: 0.9778\n",
      "Epoch 721/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0788 - accuracy: 0.9810 - val_loss: 0.0863 - val_accuracy: 0.9778\n",
      "Epoch 722/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0776 - accuracy: 0.9810 - val_loss: 0.0835 - val_accuracy: 0.9778\n",
      "Epoch 723/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0773 - accuracy: 0.9810 - val_loss: 0.0840 - val_accuracy: 0.9778\n",
      "Epoch 724/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0769 - accuracy: 0.9810 - val_loss: 0.0851 - val_accuracy: 0.9778\n",
      "Epoch 725/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0762 - accuracy: 0.9810 - val_loss: 0.0883 - val_accuracy: 0.9778\n",
      "Epoch 726/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0783 - accuracy: 0.9810 - val_loss: 0.0915 - val_accuracy: 0.9778\n",
      "Epoch 727/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0788 - accuracy: 0.9810 - val_loss: 0.0901 - val_accuracy: 0.9778\n",
      "Epoch 728/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0783 - accuracy: 0.9810 - val_loss: 0.0874 - val_accuracy: 0.9778\n",
      "Epoch 729/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0775 - accuracy: 0.9810 - val_loss: 0.0873 - val_accuracy: 0.9778\n",
      "Epoch 730/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0768 - accuracy: 0.9810 - val_loss: 0.0854 - val_accuracy: 0.9778\n",
      "Epoch 731/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0769 - accuracy: 0.9810 - val_loss: 0.0821 - val_accuracy: 0.9778\n",
      "Epoch 732/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0770 - accuracy: 0.9714 - val_loss: 0.0819 - val_accuracy: 0.9778\n",
      "Epoch 733/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0768 - accuracy: 0.9619 - val_loss: 0.0815 - val_accuracy: 0.9778\n",
      "Epoch 734/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0766 - accuracy: 0.9619 - val_loss: 0.0817 - val_accuracy: 0.9778\n",
      "Epoch 735/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0771 - accuracy: 0.9714 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
      "Epoch 736/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0761 - accuracy: 0.9714 - val_loss: 0.0822 - val_accuracy: 0.9778\n",
      "Epoch 737/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0757 - accuracy: 0.9714 - val_loss: 0.0827 - val_accuracy: 0.9778\n",
      "Epoch 738/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0755 - accuracy: 0.9810 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 739/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0760 - accuracy: 0.9810 - val_loss: 0.0854 - val_accuracy: 0.9778\n",
      "Epoch 740/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0755 - accuracy: 0.9810 - val_loss: 0.0841 - val_accuracy: 0.9778\n",
      "Epoch 741/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0752 - accuracy: 0.9810 - val_loss: 0.0841 - val_accuracy: 0.9778\n",
      "Epoch 742/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0755 - accuracy: 0.9810 - val_loss: 0.0852 - val_accuracy: 0.9778\n",
      "Epoch 743/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.0754 - accuracy: 0.9810 - val_loss: 0.0845 - val_accuracy: 0.9778\n",
      "Epoch 744/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0750 - accuracy: 0.9810 - val_loss: 0.0815 - val_accuracy: 0.9778\n",
      "Epoch 745/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0751 - accuracy: 0.9714 - val_loss: 0.0804 - val_accuracy: 0.9778\n",
      "Epoch 746/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0775 - accuracy: 0.9619 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
      "Epoch 747/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0786 - accuracy: 0.9619 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
      "Epoch 748/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0762 - accuracy: 0.9619 - val_loss: 0.0804 - val_accuracy: 0.9778\n",
      "Epoch 749/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0737 - accuracy: 0.9714 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 750/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0762 - accuracy: 0.9810 - val_loss: 0.0895 - val_accuracy: 0.9778\n",
      "Epoch 751/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0767 - accuracy: 0.9810 - val_loss: 0.0918 - val_accuracy: 0.9778\n",
      "Epoch 752/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0773 - accuracy: 0.9810 - val_loss: 0.0905 - val_accuracy: 0.9778\n",
      "Epoch 753/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0765 - accuracy: 0.9810 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
      "Epoch 754/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0751 - accuracy: 0.9810 - val_loss: 0.0858 - val_accuracy: 0.9778\n",
      "Epoch 755/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0763 - accuracy: 0.9810 - val_loss: 0.0813 - val_accuracy: 0.9778\n",
      "Epoch 756/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0739 - accuracy: 0.9810 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
      "Epoch 757/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0743 - accuracy: 0.9714 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
      "Epoch 758/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0760 - accuracy: 0.9714 - val_loss: 0.0804 - val_accuracy: 0.9778\n",
      "Epoch 759/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0744 - accuracy: 0.9619 - val_loss: 0.0792 - val_accuracy: 0.9778\n",
      "Epoch 760/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0782 - accuracy: 0.9619 - val_loss: 0.0792 - val_accuracy: 0.9556\n",
      "Epoch 761/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0771 - accuracy: 0.9619 - val_loss: 0.0792 - val_accuracy: 0.9778\n",
      "Epoch 762/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0737 - accuracy: 0.9619 - val_loss: 0.0809 - val_accuracy: 0.9778\n",
      "Epoch 763/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0731 - accuracy: 0.9810 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
      "Epoch 764/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0736 - accuracy: 0.9810 - val_loss: 0.0870 - val_accuracy: 0.9778\n",
      "Epoch 765/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0744 - accuracy: 0.9810 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
      "Epoch 766/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0742 - accuracy: 0.9810 - val_loss: 0.0849 - val_accuracy: 0.9778\n",
      "Epoch 767/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0754 - accuracy: 0.9714 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
      "Epoch 768/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0730 - accuracy: 0.9714 - val_loss: 0.0793 - val_accuracy: 0.9778\n",
      "Epoch 769/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0737 - accuracy: 0.9714 - val_loss: 0.0795 - val_accuracy: 0.9778\n",
      "Epoch 770/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0734 - accuracy: 0.9714 - val_loss: 0.0788 - val_accuracy: 0.9778\n",
      "Epoch 771/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0744 - accuracy: 0.9619 - val_loss: 0.0786 - val_accuracy: 0.9778\n",
      "Epoch 772/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0741 - accuracy: 0.9619 - val_loss: 0.0789 - val_accuracy: 0.9778\n",
      "Epoch 773/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0727 - accuracy: 0.9714 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
      "Epoch 774/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0721 - accuracy: 0.9810 - val_loss: 0.0817 - val_accuracy: 0.9778\n",
      "Epoch 775/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0725 - accuracy: 0.9810 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 776/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0720 - accuracy: 0.9810 - val_loss: 0.0823 - val_accuracy: 0.9778\n",
      "Epoch 777/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0717 - accuracy: 0.9810 - val_loss: 0.0812 - val_accuracy: 0.9778\n",
      "Epoch 778/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0715 - accuracy: 0.9810 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 779/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0715 - accuracy: 0.9810 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
      "Epoch 780/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0715 - accuracy: 0.9714 - val_loss: 0.0793 - val_accuracy: 0.9778\n",
      "Epoch 781/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0719 - accuracy: 0.9714 - val_loss: 0.0798 - val_accuracy: 0.9778\n",
      "Epoch 782/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0717 - accuracy: 0.9810 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
      "Epoch 783/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0719 - accuracy: 0.9714 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
      "Epoch 784/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0713 - accuracy: 0.9810 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 785/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0724 - accuracy: 0.9714 - val_loss: 0.0792 - val_accuracy: 0.9778\n",
      "Epoch 786/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0708 - accuracy: 0.9714 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 787/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0707 - accuracy: 0.9810 - val_loss: 0.0833 - val_accuracy: 0.9778\n",
      "Epoch 788/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0728 - accuracy: 0.9810 - val_loss: 0.0875 - val_accuracy: 0.9778\n",
      "Epoch 789/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0732 - accuracy: 0.9810 - val_loss: 0.0881 - val_accuracy: 0.9778\n",
      "Epoch 790/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0737 - accuracy: 0.9810 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
      "Epoch 791/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0729 - accuracy: 0.9810 - val_loss: 0.0859 - val_accuracy: 0.9778\n",
      "Epoch 792/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0713 - accuracy: 0.9810 - val_loss: 0.0821 - val_accuracy: 0.9778\n",
      "Epoch 793/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0692 - accuracy: 0.9810 - val_loss: 0.0785 - val_accuracy: 0.9778\n",
      "Epoch 794/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0711 - accuracy: 0.9714 - val_loss: 0.0776 - val_accuracy: 0.9778\n",
      "Epoch 795/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0733 - accuracy: 0.9619 - val_loss: 0.0775 - val_accuracy: 0.9778\n",
      "Epoch 796/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0717 - accuracy: 0.9619 - val_loss: 0.0781 - val_accuracy: 0.9778\n",
      "Epoch 797/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0700 - accuracy: 0.9714 - val_loss: 0.0797 - val_accuracy: 0.9778\n",
      "Epoch 798/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0698 - accuracy: 0.9810 - val_loss: 0.0812 - val_accuracy: 0.9778\n",
      "Epoch 799/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0698 - accuracy: 0.9810 - val_loss: 0.0825 - val_accuracy: 0.9778\n",
      "Epoch 800/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0707 - accuracy: 0.9810 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 801/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0704 - accuracy: 0.9810 - val_loss: 0.0841 - val_accuracy: 0.9778\n",
      "Epoch 802/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0709 - accuracy: 0.9810 - val_loss: 0.0846 - val_accuracy: 0.9778\n",
      "Epoch 803/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0709 - accuracy: 0.9810 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
      "Epoch 804/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0704 - accuracy: 0.9810 - val_loss: 0.0827 - val_accuracy: 0.9778\n",
      "Epoch 805/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0701 - accuracy: 0.9810 - val_loss: 0.0797 - val_accuracy: 0.9778\n",
      "Epoch 806/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0729 - accuracy: 0.9714 - val_loss: 0.0772 - val_accuracy: 0.9778\n",
      "Epoch 807/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0713 - accuracy: 0.9619 - val_loss: 0.0774 - val_accuracy: 0.9778\n",
      "Epoch 808/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0707 - accuracy: 0.9619 - val_loss: 0.0773 - val_accuracy: 0.9778\n",
      "Epoch 809/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0700 - accuracy: 0.9714 - val_loss: 0.0779 - val_accuracy: 0.9778\n",
      "Epoch 810/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0688 - accuracy: 0.9714 - val_loss: 0.0799 - val_accuracy: 0.9778\n",
      "Epoch 811/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0688 - accuracy: 0.9810 - val_loss: 0.0807 - val_accuracy: 0.9778\n",
      "Epoch 812/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0690 - accuracy: 0.9810 - val_loss: 0.0809 - val_accuracy: 0.9778\n",
      "Epoch 813/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0697 - accuracy: 0.9810 - val_loss: 0.0814 - val_accuracy: 0.9778\n",
      "Epoch 814/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0691 - accuracy: 0.9810 - val_loss: 0.0811 - val_accuracy: 0.9778\n",
      "Epoch 815/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0688 - accuracy: 0.9810 - val_loss: 0.0804 - val_accuracy: 0.9778\n",
      "Epoch 816/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0687 - accuracy: 0.9810 - val_loss: 0.0790 - val_accuracy: 0.9778\n",
      "Epoch 817/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0686 - accuracy: 0.9714 - val_loss: 0.0787 - val_accuracy: 0.9778\n",
      "Epoch 818/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0681 - accuracy: 0.9714 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 819/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0696 - accuracy: 0.9810 - val_loss: 0.0851 - val_accuracy: 0.9778\n",
      "Epoch 820/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0708 - accuracy: 0.9810 - val_loss: 0.0855 - val_accuracy: 0.9778\n",
      "Epoch 821/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0687 - accuracy: 0.9810 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
      "Epoch 822/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0675 - accuracy: 0.9810 - val_loss: 0.0775 - val_accuracy: 0.9778\n",
      "Epoch 823/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0706 - accuracy: 0.9619 - val_loss: 0.0764 - val_accuracy: 0.9778\n",
      "Epoch 824/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0700 - accuracy: 0.9619 - val_loss: 0.0764 - val_accuracy: 0.9778\n",
      "Epoch 825/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0700 - accuracy: 0.9714 - val_loss: 0.0767 - val_accuracy: 0.9778\n",
      "Epoch 826/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0693 - accuracy: 0.9714 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
      "Epoch 827/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0682 - accuracy: 0.9714 - val_loss: 0.0784 - val_accuracy: 0.9778\n",
      "Epoch 828/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.9810 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
      "Epoch 829/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0673 - accuracy: 0.9810 - val_loss: 0.0833 - val_accuracy: 0.9778\n",
      "Epoch 830/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0688 - accuracy: 0.9810 - val_loss: 0.0857 - val_accuracy: 0.9778\n",
      "Epoch 831/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0699 - accuracy: 0.9810 - val_loss: 0.0851 - val_accuracy: 0.9778\n",
      "Epoch 832/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0688 - accuracy: 0.9810 - val_loss: 0.0821 - val_accuracy: 0.9778\n",
      "Epoch 833/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0678 - accuracy: 0.9810 - val_loss: 0.0770 - val_accuracy: 0.9778\n",
      "Epoch 834/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0676 - accuracy: 0.9714 - val_loss: 0.0757 - val_accuracy: 0.9778\n",
      "Epoch 835/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0709 - accuracy: 0.9619 - val_loss: 0.0757 - val_accuracy: 0.9778\n",
      "Epoch 836/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0708 - accuracy: 0.9619 - val_loss: 0.0759 - val_accuracy: 0.9778\n",
      "Epoch 837/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0684 - accuracy: 0.9714 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
      "Epoch 838/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0671 - accuracy: 0.9714 - val_loss: 0.0792 - val_accuracy: 0.9778\n",
      "Epoch 839/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0668 - accuracy: 0.9810 - val_loss: 0.0820 - val_accuracy: 0.9778\n",
      "Epoch 840/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0674 - accuracy: 0.9810 - val_loss: 0.0829 - val_accuracy: 0.9778\n",
      "Epoch 841/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0686 - accuracy: 0.9810 - val_loss: 0.0833 - val_accuracy: 0.9778\n",
      "Epoch 842/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0680 - accuracy: 0.9810 - val_loss: 0.0821 - val_accuracy: 0.9778\n",
      "Epoch 843/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0672 - accuracy: 0.9810 - val_loss: 0.0796 - val_accuracy: 0.9778\n",
      "Epoch 844/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0664 - accuracy: 0.9810 - val_loss: 0.0778 - val_accuracy: 0.9778\n",
      "Epoch 845/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0665 - accuracy: 0.9714 - val_loss: 0.0767 - val_accuracy: 0.9778\n",
      "Epoch 846/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0669 - accuracy: 0.9714 - val_loss: 0.0772 - val_accuracy: 0.9778\n",
      "Epoch 847/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0668 - accuracy: 0.9714 - val_loss: 0.0762 - val_accuracy: 0.9778\n",
      "Epoch 848/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0668 - accuracy: 0.9714 - val_loss: 0.0763 - val_accuracy: 0.9778\n",
      "Epoch 849/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0666 - accuracy: 0.9714 - val_loss: 0.0768 - val_accuracy: 0.9778\n",
      "Epoch 850/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0659 - accuracy: 0.9714 - val_loss: 0.0776 - val_accuracy: 0.9778\n",
      "Epoch 851/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.9714 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
      "Epoch 852/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0661 - accuracy: 0.9810 - val_loss: 0.0806 - val_accuracy: 0.9778\n",
      "Epoch 853/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0663 - accuracy: 0.9810 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
      "Epoch 854/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0664 - accuracy: 0.9810 - val_loss: 0.0789 - val_accuracy: 0.9778\n",
      "Epoch 855/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0658 - accuracy: 0.9810 - val_loss: 0.0783 - val_accuracy: 0.9778\n",
      "Epoch 856/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0654 - accuracy: 0.9810 - val_loss: 0.0775 - val_accuracy: 0.9778\n",
      "Epoch 857/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0660 - accuracy: 0.9714 - val_loss: 0.0777 - val_accuracy: 0.9778\n",
      "Epoch 858/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0654 - accuracy: 0.9714 - val_loss: 0.0778 - val_accuracy: 0.9778\n",
      "Epoch 859/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0655 - accuracy: 0.9714 - val_loss: 0.0773 - val_accuracy: 0.9778\n",
      "Epoch 860/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0654 - accuracy: 0.9714 - val_loss: 0.0778 - val_accuracy: 0.9778\n",
      "Epoch 861/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0658 - accuracy: 0.9810 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
      "Epoch 862/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0662 - accuracy: 0.9810 - val_loss: 0.0784 - val_accuracy: 0.9778\n",
      "Epoch 863/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0651 - accuracy: 0.9810 - val_loss: 0.0797 - val_accuracy: 0.9778\n",
      "Epoch 864/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0653 - accuracy: 0.9810 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
      "Epoch 865/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0678 - accuracy: 0.9810 - val_loss: 0.0816 - val_accuracy: 0.9778\n",
      "Epoch 866/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0651 - accuracy: 0.9810 - val_loss: 0.0781 - val_accuracy: 0.9778\n",
      "Epoch 867/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0681 - accuracy: 0.9714 - val_loss: 0.0745 - val_accuracy: 0.9778\n",
      "Epoch 868/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0677 - accuracy: 0.9619 - val_loss: 0.0745 - val_accuracy: 0.9778\n",
      "Epoch 869/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0673 - accuracy: 0.9619 - val_loss: 0.0749 - val_accuracy: 0.9778\n",
      "Epoch 870/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0651 - accuracy: 0.9714 - val_loss: 0.0762 - val_accuracy: 0.9778\n",
      "Epoch 871/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0651 - accuracy: 0.9810 - val_loss: 0.0793 - val_accuracy: 0.9778\n",
      "Epoch 872/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0646 - accuracy: 0.9810 - val_loss: 0.0790 - val_accuracy: 0.9778\n",
      "Epoch 873/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0644 - accuracy: 0.9810 - val_loss: 0.0775 - val_accuracy: 0.9778\n",
      "Epoch 874/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0644 - accuracy: 0.9714 - val_loss: 0.0763 - val_accuracy: 0.9778\n",
      "Epoch 875/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0642 - accuracy: 0.9714 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
      "Epoch 876/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0638 - accuracy: 0.9714 - val_loss: 0.0781 - val_accuracy: 0.9778\n",
      "Epoch 877/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0651 - accuracy: 0.9810 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
      "Epoch 878/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0653 - accuracy: 0.9714 - val_loss: 0.0772 - val_accuracy: 0.9778\n",
      "Epoch 879/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0640 - accuracy: 0.9714 - val_loss: 0.0775 - val_accuracy: 0.9778\n",
      "Epoch 880/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0638 - accuracy: 0.9810 - val_loss: 0.0794 - val_accuracy: 0.9778\n",
      "Epoch 881/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0644 - accuracy: 0.9810 - val_loss: 0.0799 - val_accuracy: 0.9778\n",
      "Epoch 882/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0644 - accuracy: 0.9810 - val_loss: 0.0793 - val_accuracy: 0.9778\n",
      "Epoch 883/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0640 - accuracy: 0.9810 - val_loss: 0.0797 - val_accuracy: 0.9778\n",
      "Epoch 884/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0647 - accuracy: 0.9810 - val_loss: 0.0807 - val_accuracy: 0.9778\n",
      "Epoch 885/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0645 - accuracy: 0.9810 - val_loss: 0.0807 - val_accuracy: 0.9778\n",
      "Epoch 886/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0660 - accuracy: 0.9810 - val_loss: 0.0782 - val_accuracy: 0.9778\n",
      "Epoch 887/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0636 - accuracy: 0.9810 - val_loss: 0.0780 - val_accuracy: 0.9778\n",
      "Epoch 888/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0633 - accuracy: 0.9810 - val_loss: 0.0782 - val_accuracy: 0.9778\n",
      "Epoch 889/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0634 - accuracy: 0.9810 - val_loss: 0.0790 - val_accuracy: 0.9778\n",
      "Epoch 890/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.0788 - val_accuracy: 0.9778\n",
      "Epoch 891/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.0788 - val_accuracy: 0.9778\n",
      "Epoch 892/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.0789 - val_accuracy: 0.9778\n",
      "Epoch 893/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0634 - accuracy: 0.9810 - val_loss: 0.0778 - val_accuracy: 0.9778\n",
      "Epoch 894/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0630 - accuracy: 0.9810 - val_loss: 0.0773 - val_accuracy: 0.9778\n",
      "Epoch 895/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0632 - accuracy: 0.9810 - val_loss: 0.0776 - val_accuracy: 0.9778\n",
      "Epoch 896/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0629 - accuracy: 0.9810 - val_loss: 0.0771 - val_accuracy: 0.9778\n",
      "Epoch 897/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0639 - accuracy: 0.9714 - val_loss: 0.0762 - val_accuracy: 0.9778\n",
      "Epoch 898/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0621 - accuracy: 0.9714 - val_loss: 0.0784 - val_accuracy: 0.9778\n",
      "Epoch 899/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0634 - accuracy: 0.9810 - val_loss: 0.0813 - val_accuracy: 0.9778\n",
      "Epoch 900/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0639 - accuracy: 0.9810 - val_loss: 0.0816 - val_accuracy: 0.9778\n",
      "Epoch 901/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0641 - accuracy: 0.9810 - val_loss: 0.0811 - val_accuracy: 0.9778\n",
      "Epoch 902/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0639 - accuracy: 0.9810 - val_loss: 0.0807 - val_accuracy: 0.9778\n",
      "Epoch 903/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0637 - accuracy: 0.9810 - val_loss: 0.0783 - val_accuracy: 0.9778\n",
      "Epoch 904/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0626 - accuracy: 0.9810 - val_loss: 0.0759 - val_accuracy: 0.9778\n",
      "Epoch 905/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0639 - accuracy: 0.9714 - val_loss: 0.0737 - val_accuracy: 0.9778\n",
      "Epoch 906/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0667 - accuracy: 0.9619 - val_loss: 0.0734 - val_accuracy: 0.9778\n",
      "Epoch 907/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0648 - accuracy: 0.9714 - val_loss: 0.0750 - val_accuracy: 0.9778\n",
      "Epoch 908/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0633 - accuracy: 0.9714 - val_loss: 0.0797 - val_accuracy: 0.9778\n",
      "Epoch 909/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0632 - accuracy: 0.9810 - val_loss: 0.0823 - val_accuracy: 0.9778\n",
      "Epoch 910/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0642 - accuracy: 0.9810 - val_loss: 0.0814 - val_accuracy: 0.9778\n",
      "Epoch 911/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0634 - accuracy: 0.9810 - val_loss: 0.0811 - val_accuracy: 0.9778\n",
      "Epoch 912/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0636 - accuracy: 0.9810 - val_loss: 0.0790 - val_accuracy: 0.9778\n",
      "Epoch 913/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0623 - accuracy: 0.9810 - val_loss: 0.0777 - val_accuracy: 0.9778\n",
      "Epoch 914/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0619 - accuracy: 0.9810 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
      "Epoch 915/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0608 - accuracy: 0.9714 - val_loss: 0.0737 - val_accuracy: 0.9778\n",
      "Epoch 916/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0639 - accuracy: 0.9619 - val_loss: 0.0732 - val_accuracy: 0.9778\n",
      "Epoch 917/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0678 - accuracy: 0.9619 - val_loss: 0.0732 - val_accuracy: 0.9778\n",
      "Epoch 918/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0666 - accuracy: 0.9619 - val_loss: 0.0734 - val_accuracy: 0.9778\n",
      "Epoch 919/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0620 - accuracy: 0.9714 - val_loss: 0.0749 - val_accuracy: 0.9778\n",
      "Epoch 920/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0617 - accuracy: 0.9714 - val_loss: 0.0779 - val_accuracy: 0.9778\n",
      "Epoch 921/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0628 - accuracy: 0.9810 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
      "Epoch 922/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.0761 - val_accuracy: 0.9778\n",
      "Epoch 923/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0645 - accuracy: 0.9714 - val_loss: 0.0730 - val_accuracy: 0.9778\n",
      "Epoch 924/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0637 - accuracy: 0.9714 - val_loss: 0.0729 - val_accuracy: 0.9778\n",
      "Epoch 925/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0637 - accuracy: 0.9714 - val_loss: 0.0733 - val_accuracy: 0.9778\n",
      "Epoch 926/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0619 - accuracy: 0.9714 - val_loss: 0.0750 - val_accuracy: 0.9778\n",
      "Epoch 927/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0614 - accuracy: 0.9714 - val_loss: 0.0769 - val_accuracy: 0.9778\n",
      "Epoch 928/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.0762 - val_accuracy: 0.9778\n",
      "Epoch 929/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0609 - accuracy: 0.9714 - val_loss: 0.0737 - val_accuracy: 0.9778\n",
      "Epoch 930/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0625 - accuracy: 0.9714 - val_loss: 0.0728 - val_accuracy: 0.9778\n",
      "Epoch 931/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0628 - accuracy: 0.9714 - val_loss: 0.0729 - val_accuracy: 0.9778\n",
      "Epoch 932/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0620 - accuracy: 0.9714 - val_loss: 0.0740 - val_accuracy: 0.9778\n",
      "Epoch 933/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0603 - accuracy: 0.9714 - val_loss: 0.0757 - val_accuracy: 0.9778\n",
      "Epoch 934/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0605 - accuracy: 0.9714 - val_loss: 0.0777 - val_accuracy: 0.9778\n",
      "Epoch 935/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 0.0786 - val_accuracy: 0.9778\n",
      "Epoch 936/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0609 - accuracy: 0.9810 - val_loss: 0.0786 - val_accuracy: 0.9778\n",
      "Epoch 937/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0612 - accuracy: 0.9810 - val_loss: 0.0779 - val_accuracy: 0.9778\n",
      "Epoch 938/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0609 - accuracy: 0.9810 - val_loss: 0.0771 - val_accuracy: 0.9778\n",
      "Epoch 939/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0604 - accuracy: 0.9714 - val_loss: 0.0762 - val_accuracy: 0.9778\n",
      "Epoch 940/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0603 - accuracy: 0.9714 - val_loss: 0.0762 - val_accuracy: 0.9778\n",
      "Epoch 941/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0609 - accuracy: 0.9714 - val_loss: 0.0770 - val_accuracy: 0.9778\n",
      "Epoch 942/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0602 - accuracy: 0.9810 - val_loss: 0.0770 - val_accuracy: 0.9778\n",
      "Epoch 943/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0601 - accuracy: 0.9810 - val_loss: 0.0760 - val_accuracy: 0.9778\n",
      "Epoch 944/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0600 - accuracy: 0.9714 - val_loss: 0.0741 - val_accuracy: 0.9778\n",
      "Epoch 945/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0600 - accuracy: 0.9714 - val_loss: 0.0735 - val_accuracy: 0.9778\n",
      "Epoch 946/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0603 - accuracy: 0.9714 - val_loss: 0.0729 - val_accuracy: 0.9778\n",
      "Epoch 947/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0606 - accuracy: 0.9714 - val_loss: 0.0731 - val_accuracy: 0.9778\n",
      "Epoch 948/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0604 - accuracy: 0.9714 - val_loss: 0.0740 - val_accuracy: 0.9778\n",
      "Epoch 949/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0597 - accuracy: 0.9714 - val_loss: 0.0739 - val_accuracy: 0.9778\n",
      "Epoch 950/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0603 - accuracy: 0.9714 - val_loss: 0.0738 - val_accuracy: 0.9778\n",
      "Epoch 951/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0589 - accuracy: 0.9714 - val_loss: 0.0761 - val_accuracy: 0.9778\n",
      "Epoch 952/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0597 - accuracy: 0.9810 - val_loss: 0.0795 - val_accuracy: 0.9778\n",
      "Epoch 953/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.0797 - val_accuracy: 0.9778\n",
      "Epoch 954/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0603 - accuracy: 0.9810 - val_loss: 0.0773 - val_accuracy: 0.9778\n",
      "Epoch 955/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0606 - accuracy: 0.9714 - val_loss: 0.0739 - val_accuracy: 0.9778\n",
      "Epoch 956/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0601 - accuracy: 0.9714 - val_loss: 0.0752 - val_accuracy: 0.9778\n",
      "Epoch 957/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0591 - accuracy: 0.9714 - val_loss: 0.0759 - val_accuracy: 0.9778\n",
      "Epoch 958/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0590 - accuracy: 0.9714 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
      "Epoch 959/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.0776 - val_accuracy: 0.9778\n",
      "Epoch 960/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0606 - accuracy: 0.9714 - val_loss: 0.0759 - val_accuracy: 0.9778\n",
      "Epoch 961/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0589 - accuracy: 0.9714 - val_loss: 0.0753 - val_accuracy: 0.9778\n",
      "Epoch 962/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0587 - accuracy: 0.9714 - val_loss: 0.0751 - val_accuracy: 0.9778\n",
      "Epoch 963/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0589 - accuracy: 0.9714 - val_loss: 0.0746 - val_accuracy: 0.9778\n",
      "Epoch 964/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0582 - accuracy: 0.9714 - val_loss: 0.0731 - val_accuracy: 0.9778\n",
      "Epoch 965/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0590 - accuracy: 0.9714 - val_loss: 0.0726 - val_accuracy: 0.9778\n",
      "Epoch 966/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0608 - accuracy: 0.9714 - val_loss: 0.0719 - val_accuracy: 0.9778\n",
      "Epoch 967/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0605 - accuracy: 0.9714 - val_loss: 0.0723 - val_accuracy: 0.9778\n",
      "Epoch 968/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0584 - accuracy: 0.9714 - val_loss: 0.0745 - val_accuracy: 0.9778\n",
      "Epoch 969/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0583 - accuracy: 0.9714 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
      "Epoch 970/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0774 - val_accuracy: 0.9778\n",
      "Epoch 971/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.0754 - val_accuracy: 0.9778\n",
      "Epoch 972/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0582 - accuracy: 0.9714 - val_loss: 0.0743 - val_accuracy: 0.9778\n",
      "Epoch 973/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0590 - accuracy: 0.9714 - val_loss: 0.0739 - val_accuracy: 0.9778\n",
      "Epoch 974/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0579 - accuracy: 0.9714 - val_loss: 0.0757 - val_accuracy: 0.9778\n",
      "Epoch 975/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0787 - val_accuracy: 0.9778\n",
      "Epoch 976/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.0814 - val_accuracy: 0.9778\n",
      "Epoch 977/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0604 - accuracy: 0.9810 - val_loss: 0.0808 - val_accuracy: 0.9778\n",
      "Epoch 978/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0599 - accuracy: 0.9810 - val_loss: 0.0796 - val_accuracy: 0.9778\n",
      "Epoch 979/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 0.0785 - val_accuracy: 0.9778\n",
      "Epoch 980/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.0777 - val_accuracy: 0.9778\n",
      "Epoch 981/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0582 - accuracy: 0.9714 - val_loss: 0.0734 - val_accuracy: 0.9778\n",
      "Epoch 982/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0578 - accuracy: 0.9714 - val_loss: 0.0722 - val_accuracy: 0.9778\n",
      "Epoch 983/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0587 - accuracy: 0.9714 - val_loss: 0.0720 - val_accuracy: 0.9778\n",
      "Epoch 984/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0583 - accuracy: 0.9714 - val_loss: 0.0736 - val_accuracy: 0.9778\n",
      "Epoch 985/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0577 - accuracy: 0.9714 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
      "Epoch 986/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0776 - val_accuracy: 0.9778\n",
      "Epoch 987/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0586 - accuracy: 0.9810 - val_loss: 0.0792 - val_accuracy: 0.9778\n",
      "Epoch 988/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
      "Epoch 989/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0779 - val_accuracy: 0.9778\n",
      "Epoch 990/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.0760 - val_accuracy: 0.9778\n",
      "Epoch 991/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0573 - accuracy: 0.9714 - val_loss: 0.0746 - val_accuracy: 0.9778\n",
      "Epoch 992/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0573 - accuracy: 0.9714 - val_loss: 0.0740 - val_accuracy: 0.9778\n",
      "Epoch 993/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0571 - accuracy: 0.9714 - val_loss: 0.0744 - val_accuracy: 0.9778\n",
      "Epoch 994/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0571 - accuracy: 0.9714 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
      "Epoch 995/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0573 - accuracy: 0.9714 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
      "Epoch 996/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0575 - accuracy: 0.9714 - val_loss: 0.0754 - val_accuracy: 0.9778\n",
      "Epoch 997/1000\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0584 - accuracy: 0.9714 - val_loss: 0.0745 - val_accuracy: 0.9778\n",
      "Epoch 998/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0560 - accuracy: 0.9714 - val_loss: 0.0778 - val_accuracy: 0.9778\n",
      "Epoch 999/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.0811 - val_accuracy: 0.9778\n",
      "Epoch 1000/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 0.0781 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3ca4284760>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(x = X_treinamento,\n",
    "           y = y_treinamento, \n",
    "           epochs = 1000,\n",
    "           validation_data = (X_teste, y_teste) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e8269-294a-43cd-8ca8-80614db5eca7",
   "metadata": {},
   "source": [
    "Como podemos ver, depois de 1000 epochs, a rede atingiu uma precisão maior que **98 %**. A maior precisão que conseguimos com respeito aos outros modelos já testados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57727fb8-2b6d-442b-9a5a-964a2347650f",
   "metadata": {},
   "source": [
    "## Precisão do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e1080-b33b-40e2-b843-70d72ee4a2b4",
   "metadata": {},
   "source": [
    "Para gerar um array com a previsão do modelo, usamos o método ```predict```, fornecendo os valores x de teste como nos demais modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab3760c-e5f6-4e4e-9cee-6f8a9231d8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.27450186e-11, 7.66148805e-05, 9.99923348e-01],\n",
       "       [1.64250814e-04, 9.96276319e-01, 3.55934515e-03],\n",
       "       [9.99980569e-01, 1.93792584e-05, 7.88242943e-22],\n",
       "       [4.20613058e-11, 1.99648854e-03, 9.98003542e-01],\n",
       "       [9.99538064e-01, 4.61985124e-04, 1.42141459e-17],\n",
       "       [4.98596607e-13, 2.13485764e-05, 9.99978662e-01],\n",
       "       [9.99780953e-01, 2.19091453e-04, 3.24138064e-18],\n",
       "       [4.81294046e-05, 9.90557432e-01, 9.39441845e-03],\n",
       "       [1.59432093e-05, 9.67495859e-01, 3.24882641e-02],\n",
       "       [4.72837797e-04, 9.98495936e-01, 1.03129004e-03],\n",
       "       [1.28788376e-08, 3.04095186e-02, 9.69590485e-01],\n",
       "       [1.46645732e-04, 9.96375859e-01, 3.47741460e-03],\n",
       "       [4.88008700e-05, 9.85498309e-01, 1.44529752e-02],\n",
       "       [2.33477331e-05, 9.45126176e-01, 5.48505299e-02],\n",
       "       [3.32486707e-05, 9.53299761e-01, 4.66669314e-02],\n",
       "       [9.99889612e-01, 1.10394954e-04, 2.87392168e-19],\n",
       "       [4.92113468e-05, 9.47949588e-01, 5.20012043e-02],\n",
       "       [7.35133654e-05, 9.60531294e-01, 3.93951721e-02],\n",
       "       [9.98166502e-01, 1.83355995e-03, 1.62129084e-15],\n",
       "       [9.99922752e-01, 7.72283238e-05, 9.69500268e-20],\n",
       "       [7.73961606e-09, 5.37717715e-03, 9.94622827e-01],\n",
       "       [7.00087403e-05, 9.34919477e-01, 6.50105402e-02],\n",
       "       [9.97965932e-01, 2.03412003e-03, 7.42579279e-16],\n",
       "       [9.98190820e-01, 1.80912390e-03, 2.85301216e-15],\n",
       "       [7.07944196e-07, 1.71429008e-01, 8.28570306e-01],\n",
       "       [9.99965072e-01, 3.49456859e-05, 5.66867585e-20],\n",
       "       [9.98983920e-01, 1.01609400e-03, 9.78290695e-17],\n",
       "       [2.18831614e-04, 9.97738481e-01, 2.04264349e-03],\n",
       "       [3.28876683e-03, 9.96245444e-01, 4.65750258e-04],\n",
       "       [9.98647153e-01, 1.35289528e-03, 4.34226094e-16],\n",
       "       [4.86042140e-08, 5.60101941e-02, 9.43989754e-01],\n",
       "       [6.81076999e-05, 9.03081179e-01, 9.68507379e-02],\n",
       "       [9.99672771e-01, 3.27235961e-04, 3.47884248e-18],\n",
       "       [1.50385938e-06, 2.60492325e-01, 7.39506245e-01],\n",
       "       [7.00616301e-12, 1.37400479e-04, 9.99862552e-01],\n",
       "       [3.44128901e-04, 9.79607344e-01, 2.00484842e-02],\n",
       "       [9.99653101e-01, 3.46868794e-04, 1.31138319e-18],\n",
       "       [1.70568512e-07, 8.83707255e-02, 9.11629140e-01],\n",
       "       [2.24847143e-04, 9.91979003e-01, 7.79618090e-03],\n",
       "       [3.35265097e-04, 9.96890008e-01, 2.77474034e-03],\n",
       "       [1.00125630e-09, 4.77476465e-03, 9.95225191e-01],\n",
       "       [9.99561369e-01, 4.38602758e-04, 3.28147280e-17],\n",
       "       [8.85446294e-09, 1.35461790e-02, 9.86453831e-01],\n",
       "       [9.98080254e-01, 1.91974896e-03, 2.05672750e-15],\n",
       "       [9.99836922e-01, 1.63001023e-04, 3.19073263e-19]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes = modelo.predict(X_teste)\n",
    "\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8c7a9d-a607-4af1-b2f1-de9fea9ed5ac",
   "metadata": {},
   "source": [
    "Como podemos ver, ele retorna uma matriz onde cada elemento é uma probabilidade. Por exemplo, na linha 1 temos que o primeiro elemento é 1.27450186e-11 (menor que 1%). Isso significa que a chance da primeira linha ser do tipo Setosa é praticamente desprezível.\n",
    "\n",
    "Dado que os valores de teste esão no formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55d5e0b9-5fab-42d9-87ad-0060ac8a985e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c06826-d406-4263-9176-e45dfd832162",
   "metadata": {},
   "source": [
    "então vamos transformar os dois objetos em listas, onde cada elemento corresponde ao índice do maior valor de cada linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70cbc089-814c-47b7-8d36-351d0321a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_teste_matrix = [argmax(t) for t in y_teste]\n",
    "\n",
    "y_previsao_matrix = [argmax(t) for t in previsoes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0e84749-ddbc-4052-80ef-e2b3304ece76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_previsao_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4bb61e0-6f52-421f-b662-676f7c241486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1121d65d-0a7b-482f-afc9-607a82e93cf6",
   "metadata": {},
   "source": [
    "Agora sim podemos calcular a matriz de confusão do problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89a0226e-6f2a-4972-ad6e-f33a6391e992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  0],\n",
       "       [ 0, 17,  1],\n",
       "       [ 0,  0, 11]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusao = confusion_matrix(y_teste_matrix, y_previsao_matrix)\n",
    "\n",
    "confusao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301b13b-ede9-46ba-a677-2f30f6f800c4",
   "metadata": {},
   "source": [
    "**APENAS 1 ELEMENTO ESTAVA ERRADO.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c437ac9-8b62-4fac-8f7a-12946f6eb971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
